<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_lc3_4vy_zs">
 <title>Replication</title>
 <shortdesc>Within a single cluster, Couchbase Server employs peer-to-peer replication. It automatically creates copies of active data, distributes those replicas across the nodes in the cluster, ensuring that every copy is located on a separate node, and then continues to maintain the replicas over time.</shortdesc>
 <conbody>
  <p>Couchbase supports up to 3 replicas (which means up to 4 copies of data). Peer-to-peer
   replication allows for the best performance and resource utilization as well as eliminating
   possible bottlenecks and single points of failure. Each node replicates separate slices
   (vBuckets) of its active data to multiple other nodes so that the no one node is a replica for
   any other one node. <fig id="fig_cwz_qkz_zs">
    <title>Intra-cluster replication providing data redundancy</title>
    <image placement="break" href="images/intra-cluster-replication.png" width="250"
     id="image_dwz_qkz_zs"/>
   </fig></p>
  
  <p>If a node goes down, Couchbase Server recovers that data  by activating the replicas that already exist elsewhere in the cluster. This  process is known as failover. Failover can be automatic or manual, and failover can be scripted to satisfy specialized requirements.</p>
  
  <p>The redundancy that replication provides protects against the loss of data on any single node and helps increase data availability by allowing recovery from hardware failures and service interruptions. Replication also further increases read availability by servicing requests in the short time that an active copy is unavailable before failover takes place. </p>
  
  <p>As mentioned earlier, by default replicas are only for the purpose of high availability and are not used in the normal serving of data.  This allows Couchbase to be strongly consistent and applications immediately read their own writes by not ever requesting data from a node that it is not active on.  The managed caching layer of the data service allows for extremely high throughput and low latency with mixed workloads to either a small or large number of documents on a given node.  It is not uncommon to measure response times of under 1ms at the 99th percentile of 100â€™s of thousands of requests per second to a single node.</p>
  
  <p>Replicating data to different data centers using <xref href="../ha-dr/ha-dr-intro.dita#concept_rwn_1vf_ps/geo-dist-and-xdcr">XDCR</xref> provides locality
      and increased availability of data for applications. </p>
 </conbody>
</concept>
