<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="whats-new">
  <title>What's New in Version 4.6.0?</title>
  <body> 
    <p>Couchbase Server is a comprehensive, general purpose database that supports broad set of web,
      mobile, and IoT applications. </p>
    <p>Couchbase Server 4.6 delivers some exciting capabilities for cross datacenter replication,
      security, query, tools, and application development. This release also adds support for
      Microsoft Windows 10 Anniversary Edition and Mac OS Sierra. For more information, see <xref
        href="../install/install-platforms.dita">Supported Platforms</xref>.</p>
    
    <section><title>Cross Datacenter Replication</title>
    <dl>
      <dlentry>
        <dt>Cross Datacenter Replication with Timestamp-based Conflict Resolution</dt>
        <dd>This release introduces a new option to resolve conflicts with XDCR using timestamps.
            With this option, conflicts are resolved by comparing timestamps of conflicting
            documents. The timestamp-based conflict resolution provides a new option for
            applications which want users to continue seeing the latest change or version, no matter
            when conflicts are resolved in the background. Server set timestamp on every document
            combines the best of logical and physical clocks and captures the causality relationship
            like logical clocks. For more information, see <xref
              href="../xdcr/xdcr-conflict-resolution.dita#conflict-resolution/timestamp-based-conflict-resolution"
              />.</dd>
      </dlentry>
    </dl>
    </section>
    <section><title>Security</title>
      <dl>
        <dlentry>
          <dt>Hardened Security with Pluggable Authentication Module</dt>
          <dd>By adding support for Pluggable Authentication Modules (PAM), this release of Couchbase
            Server enables you to centralize and synchronize password management across servers. You
            can use existing password management services such as Linux /etc/shadow for a Couchbase
            cluster. You can also control password expiration rules and other password policies. PAM
            Authentication in Couchbase is available only on Linux platform and is an Enterprise only
            feature. For more information, see <xref
              href="../security/security-pam-auth.dita"/>.</dd>
        </dlentry>
        <dlentry>
        <dt>Secret Management</dt>
          <dd>With the Secret Management functionality, Couchbase Server provides you a way to
            securely manage server secrets which helps hardening of Couchbase Server. This feature
            allows businesses to fulfill important requirements around their server secrets needed
            for compliance. For more information, see <xref
              href="../security/secret-mgmt.dita">Secret Management and
              Hardening</xref>.</dd>
      </dlentry>
      </dl>
    </section>
    <section><title>N1QL Enhancements</title><p>N1QL introduces a number of new functions and performance optimizations in the Couchbase Server 4.6 Query engine. 
      <dl>
      <dlentry>
        <dt>String Functions</dt>
        <dd>The following new string functions are added. For more details and examples, see <xref
                href="../n1ql/n1ql-language-reference/stringfun.dita"/>.<ul>
                <li><codeph>TOKENS()</codeph> - Tokenizes given string or JSON object based on
                  specified delimiter and options. When used with GSI functional indexes, this
                  function can bring huge performance improvement to certain queries on text
                  fields.</li>
                <li><codeph>REVERSE()</codeph> - This function reverses the input string.</li>
              </ul></dd>
      </dlentry>
      </dl><dl>
        <dlentry>
          <dt>Date Functions</dt>
          <dd>The following new date functions are added. For more details and examples, see <xref
                href="../n1ql/n1ql-language-reference/datefun.dita"/>.<ul>
                <li><codeph>ARRAY_DATE_RANGE(expression1, expression2, part [,n])</codeph> - Returns
                  an array of dates from the start date until the end date, incrementing the
                  specified ‘part’ of the date/time by ‘n’.</li>
                <li>
                  <codeph>CLOCK_LOCAL()</codeph> - Returns the local time at the server.</li>
                <li><codeph>CLOCK_UTC()</codeph> - Returns the Coordinated Universal Time.</li>
                  <li><codeph>CLOCK_TZ()</codeph> - Returns the time in the specified timezone</li>
                  <li><codeph>DATE_FORMAT_STR(expression,fmt)</codeph> - Converts a given date
                  string parameter to the specified format.</li>
                  <li><codeph>MILLIS_TO_LOCAL(millis,fmt)</codeph> - Converts the UNIX milliseconds
                  into local time in the specified format.</li>
                  <li><codeph>MILLIS_TO_TZ(millis,zone)</codeph> - Converts the UNIX milliseconds
                  into time in the specified timezone. This is alias of
                    <codeph>MILLIS_TO_ZONE_NAME(millis,zone)</codeph> that is available in earlier
                  versions.</li>
                  <li><codeph>NOW_LOCAL(void)</codeph> - Returns the current local time at the
                  server. This is same as <codeph>CLOCK_LOCAL()</codeph> function.</li>
                  <li><codeph>NOW_TZ(zone)</codeph> - Returns the current time in specified
                  timezone.</li>
                  <li><codeph>NOW_UTC()</codeph> - Returns the current time in UTC.</li>
                  <li><codeph>STR_TO_TZ(strdate,zone)</codeph>- Returns the specified date string in
                  the specified timezone. This is alias of
                    <codeph>STR_TO_ZONE_NAME(strdate,zone)</codeph> available in earlier
                  versions.</li>
                  <li><codeph>DATE_PART_MILLIS(expression, part [,timezone])</codeph>- A new
                    <codeph>timezone</codeph> parameter is added to this existing function. This
                  function first converts the date in UNIX milliseconds into a date string in the
                  specified timezone, and then returns the corresponding part.</li>
              </ul></dd>
        </dlentry>
      </dl></p>
      <p>
        <dl>
          <dlentry>
            <dt>Array Functions</dt>
            <dd>The following new Array functions are added. For more details and examples, see
                <xref
                href="../n1ql/n1ql-language-reference/arrayfun.dita"
                >Array Functions</xref>.<ul id="ul_usn_cqx_4y">
                  <li><codeph>ARRAY_UNION(arr1, arr2, ...)</codeph> - Returns set union of the input
                  arrays. It retains only distinct array elements in unspecified order.</li>
                <li><codeph>ARRAY_SYMDIFF(arr1, arr2) ARRAY_SYMDIFF1(arr1, arr2)</codeph> - This
                  function returns disjunctive union of two arrays, that is
                    <codeph>ARRAY_UNION()</codeph> minus <codeph>ARRAY_INTERSECTION()</codeph>.
                  Result includes values that are in only one of the arrays. </li>
                  <li><codeph>ARRAY_SYMDIFFN(arr1, arr2)</codeph> - This function returns symmetric
                  difference of multiple input arrays. Result includes values that are in odd number
                  of the input arrays.</li>
              </ul></dd><dd>The following Array functions are updated to take variable number of arguments:<ul
                id="ul_urn_wdy_4y">
                <li><codeph>ARRAY_APPEND()</codeph></li>
                <li><codeph>ARRAY_CONCAT()</codeph></li>
                <li><codeph>ARRAY_INSERT()</codeph></li>
                <li><codeph>ARRAY_PREPEND()</codeph></li>
                <li><codeph>ARRAY_PUT()</codeph></li>
                <li><codeph>ARRAY_REMOVE()</codeph></li>
              </ul></dd>
          </dlentry>
        </dl>
      </p>
      <p>
        <dl>
          <dlentry>
            <dt>Object Functions</dt>
            <dd>The following new object functions are added. For more details and examples, see
                <xref href="../n1ql/n1ql-language-reference/objectfun.dita"/>.<ul
                id="ul_utp_cqx_4y">
                <li><codeph>OBJECT_CONCAT()</codeph> - Concatenates two JSON objects and returns an
                  object that includes fields from all input objects.</li>
                <li><codeph>OBJECT_REMOVE()</codeph> - Removes specified fields from the input
                  object.</li>
              </ul></dd>
          </dlentry><dlentry>
            <dt>Performance Improvements</dt>
            <dd>Couchbase Server 4.6 includes over 35 optimizations in the N1QL query engine spread
              across query planning, better index selection, more efficient query processing
              algorithms, operator pushdown to index, and efficient resource management. These
              optimizations are described below: <ul id="ul_kqw_ghy_4y">
                <li><b>Block Nested Loop JOINs</b>: The JOIN algorithm is improved to perform batch
                  processing through various stages of the JOIN, such as fetching documents from
                  data-service and the nested loop join of documents from the left side and right
                  side keyspaces/buckets.</li>
                <li><b>Covering Index Optimizations</b>: <ul>
                    <li>Queries using BETWEEN are optimized to leverage covering indexes.</li>
                    <li>Query planning is optimized to pick a covering non-array index over an array
                      index when both indexes are available and qualifying for a query.</li>
                    <li>Query planner is optimized to pick the shortest covering index when multiple
                      covering indexes are available. In earlier version, first encountered index
                      was used.</li>
                    <li>Improved right side covering of INDEX JOIN.</li>
                  </ul></li>
                <li><b>IntersectScan Optimizations</b>: This is a query operator to use multiple
                  qualifying indexes for a query with conjunctive predicates. Multiple enhancements
                  are made to optimally use IntersectScans (that is, to avoid or leverage them appropriately).<ul>
                    <li>Avoid IntersectScan on duplicate/replica indexes with same definition, or
                      when the indexes have overlapping definitions (in which case pick the minimal
                      index). In such case, query planner is optimized to pick a single index.</li>
                    <li>Use IntersectScan on multiple array-indexes for a query with UNNEST
                      operation.</li>
                    <li>Use IntersectScan on non-array index and an array-index, when an
                      UNNEST-query has no qualified covering index. Earlier versions use the
                      secondary scan in such case.</li>
                  </ul></li>
                <li><b>IndexCountScan Optimizations</b>: This is a query operator that makes
                    <codeph>COUNT()</codeph> operations efficient by pushing down the operation to
                  Index whenever possible. Following scenarios are enabled to pushdown
                    <codeph>COUNT()</codeph>.<ul>
                    <li>Queries with conjunctive/AND predicates with IN/WITHIN clause having all
                      static values. Note that, IndexCountScan pushdown doesn’t happen when
                      where-clause contains an OR predicate or uses query-parameters in the
                      IN/WITHIN clause. </li>
                    <li>Queries using <codeph>BETWEEN</codeph>, <codeph>&lt;</codeph>, and
                        <codeph>></codeph> operators with parameters in the WHERE clause.</li>
                  </ul></li>
                <li>Improved HTTP performance between client and Query service for transferring
                  query results.</li>
                <li>Improved performance of queries with ORDER BY ASC clause, by leveraging index
                  order in more scenarios, such as when leading index keys are not present in ORDER
                  BY but have fixed/constant values in the query WHERE clause. </li>
              </ul></dd>
          </dlentry>
        </dl>
      </p>
    </section>
    <section><title>Full Text Search [Developer Preview]</title>
      <dl>
        <dlentry>
          <dt>Faster Full Text Indexing and Queries</dt>
          <dd>Full text search (FTS) in 4.6 is noticeably snappier due to many performance
            enhancements, small and large. Many improvements are due to enhancements made in <xref
              href="http://www.blevesearch.com/" format="html" scope="external">bleve</xref>, the
            full-text search and indexing Go library that powers FTS.<p>The biggest single
              contributor to performance improvements is MossStore, the new default KV store
              underlying full text indexes. FTS has for some time used <xref
                href="https://github.com/couchbase/moss" format="html" scope="external">Moss</xref>
              to improve query and especially indexing performance. <xref
                href="https://github.com/couchbase/moss" format="html" scope="external">Moss</xref>,
              which stands for “Memory-oriented sorted segments”, is a simple, fast, persistable,
              ordered key value collection implemented as a pure Golang library.</p><p>MossStore
              extends Moss so that it efficiently persists sorted segments to disk when necessary.
              MossStore is recommended for all use cases, but advanced users can still change back
              to ForestDB by setting the “store” “kvStoreName” property to “forestdb”.</p></dd>
        </dlentry>
        <dlentry>
          <dt>Index Type Mapping by Keys</dt>
          <dd>You can now create custom index mappings by document type when the type is specified
            in the document key. Previously, you could create custom index mappings for different
            types of objects, but only when the type was indicated by an attribute in the JSON
            document body. (By default, FTS looks for an attribute named “type”). With this
            enhancement, it’s easier to support the common data modeling style in which the document
            type is indicated by a portion of the key, for example, “user::will.gardella”. See <xref
              href="../fts/fts-creating-indexes.dita#topic_ksl_wwk_1v/fts-index-mapping">Index Type Mapping By Keys</xref> for more information.</dd>
        </dlentry>
        <dlentry>
          <dt>Sorting</dt>
          <dd>You can now sort search results by any indexed field. In the previous releases, search
            results are always sorted by descending score so that highest scoring results are listed
            first. This is still the default sort order, so if you don’t specify a sort order,
            you’re unlikely to notice any difference. See <xref
              href="../fts/fts-sorting.dita#topic_l2x_pkx_vx"/> for more information.</dd>
        </dlentry>
      </dl>
    </section>
    <section><title>CBImport and CBExport Tools [Developer Preview]</title>
      <p>This release introduces tools to import and export data to and from Couchbase Server. <codeph>cbimport</codeph> imports data from a CSV file or a JSON document, and <codeph>cbexport</codeph> exports data as a JSON document. For more information, see <xref href="../tools/cbimport.dita"/> and <xref href="../tools/cbexport.dita"/>.</p>
    </section>
    <section><title>Data Structures for Simplified Application Development</title><p dir="ltr"
        >Couchbase is extending the programming model with the new Datastructure SDK feature,
        further simplifies application development. Building on Couchbase Server 4.5’s support for
        sub-document level changes, Couchbase has now added support for lists, maps, sets, and
        queues to libraries for Java, .NET, Node.js, and PHP among other platforms.
      </p>Datastructure is built on standard JSON giving developers access to the complete set of
      Couchbase’s best-in-class data access options, including N1QL and Full Text Search. The new
      structures and other services work seamlessly with the same underlying data representation.
      For example, a Java developer can use the Java Collections Framework with the list interface
      and still use SQL standard query to access the same data from N1QL.</section>
    <section><title>Big Data Connectors for Spark and Kafka</title>
      <dl>
        <dlentry>
          <dt>Spark Connector 2.0</dt>
          <dd><p dir="ltr">Support for Spark 2.0 is now available, including the <b>Structured
                Streaming API</b> that enables continuous analysis of operational data.</p>Dynamic
            topology is now automatically supported, making it easier to manage analytics processing
            in a changing production environment. Stream performance has been significantly
            improved. <p>For more information, see <xref
                href="../connectors/spark-2.0/spark-intro.dita#concept_l11_ppm_pp"/>.</p></dd>
        </dlentry>
        <dlentry>
          <dt>Kafka Connector 3.1 </dt>
          <dd>The Couchbase Kafka Connector makes it easier to build scalable and reliable streaming
            data services between Apache Kafka and other systems. As of version 3.0, it has been
            re-written to leverage <b>Kafka Connect</b>, which standardizes the management of the
            connector, enables end-to-end monitoring, and supports dashboard tools such as <xref
              href="http://docs.confluent.io/3.0.0/control-center/docs/index.html#control-center"
              format="html" scope="external">Confluent Control Center</xref>. </dd>
          <dd><b>Kafka Streams</b> make it easier to write <xref
              href="http://docs.confluent.io/3.1.1/streams/" format="html" scope="external"
              >stream-based applications</xref>. You can now use Couchbase as a <b>Kafka Source</b>
            or <b>Kafka Sink</b> based on the new Kafka Connect protocol (supported on Kafka 0.9 or
            newer). With filtering capability you can build an intelligent stream processing
            environment easily. </dd>
          <dd>Configuration and management of the Connector is made easier with a couple powerful
            changes, including <b>Dynamic Topology</b> support for rebalance and failover scenarios.
              <b>SSL support</b> can now easily be enabled simply by setting a configuration
            property. </dd>
          <dd>Various important efficiency improvements make better use of connections and resources
            with the Connector. <ul id="ul_zhy_1gy_4y">
              <li>The Connector now has <b>node partition distribution awareness</b>, allowing the
                cluster map to send DCP stream partitions to Kafka tasks, reducing socket
                connections. </li>
              <li>The Connector now <b>maintains replication state</b> and can resume streaming from
                where it left off after a temporary disconnection. </li>
              <li><b>Faster serialization</b> is now possible as Couchbase sequence numbers are
                persisted as Kafka Connect offsets instead of as Zookeeper nodes. </li>
              <li><b>Bulk mode</b> for DCP Snapshots is a new option, making offsets only committed
                in Kafka once the entire snapshot is received - avoiding duplicate retransmissions
                of mutations.</li>
            </ul>
          </dd>
        </dlentry>
      </dl>
    </section>
  </body>
</topic>
