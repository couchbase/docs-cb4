<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic xml:lang="en-us" id="topic13047">
	<title>Sizing guidelines</title>
	<shortdesc>The primary considerations for sizing a Couchbase Server cluster are the number of
		nodes and node size.</shortdesc>
	<body>
		<p>When you are planning to deploy a Couchbase Server cluster, the most common and important questions are the number and size of the nodes. 
			With introduction of MDS (Multi-Dimensional Scaling), sizing is becoming more challenging and these 
			guidelines aim to help you better size your clusters. 
		</p>
		<!--<p>When sizing your Couchbase Server cluster, ask the following questions:</p>
		<ul>
			<li>How many nodes do I need?</li>
			<li>How large (RAM, CPU, disk space) must those nodes be?</li>
		</ul>
		<p>To determine the number of nodes needed for a cluster, consider the following:</p>
		<ul>
			<li>RAM</li>
			<li>Disk throughput and sizing</li>
			<li>Network bandwidth</li>
			<li>Data distribution and safety</li>
		</ul>
		<p>Due to the in-memory nature of Couchbase Server, RAM is usually the determining factor for
			sizing. However, the primary sizing factor depends on the actual data set and the
			information being stored. For example:</p>
		<ul>
			<li>If you have a very small data set with a very high load, calculate the size based more on the
				network bandwidth than RAM.</li>
			<li>If you have a very high write rate, allocate more nodes to support the disk throughput that
				is needed to persist all that data (and likely more RAM to buffer the incoming
				writes).</li>
			<li>Even with a very small data set under low load, a minimum of four nodes are recommended for
				proper distribution and safety.</li>
		</ul>
		<p>The capacity of your cluster (RAM, disk, CPU, or network) can be increased by increasing the
			number of nodes within the cluster, since each limit is increased linearly as the
			cluster size is increased.</p>
		
		<dl>
			<dlentry>
				<dt>RAM sizing</dt>
				<dd>RAM is usually the most critical sizing parameter. It is also the one that can have most
					impact on performance and stability.</dd>
			</dlentry>
		</dl>
		<dl
			>
			<dlentry>
				<dt>Working set</dt>
				<dd>The working set is the data that the client application actively uses at any point in time.
					Ideally, all of the working set lives in memory, which impacts the amount of
					needed memory.</dd>
			</dlentry>
		</dl>
<dl>
	<dlentry>
		<dt>Memory quota</dt>
		<dd>It is very important that your Couchbase Server cluster’s size corresponds to the working set size
					and total data you expect. The goal is to size the available RAM so that all
					your document IDs, the document ID meta data, and the working set values fit.
					The memory must rest just below the point at which Couchbase Server will
					start evicting values to disk (the High Water Mark).</dd>
	</dlentry>
</dl>
		
			
			<note type="important">All your machine's RAM cannot be allocated to a Couchbase Server node
				(<codeph>per_node_ram_quota</codeph> parameter) because other programs might be
			running on your machine.</note>
			
			<draft-comment author="marija">The following paragraph was added to resolve DOC-477. It has to be
			verified since  the content of this page has changed.</draft-comment>
		<p>Leaving additional available RAM will allow the operating 
			system memory to use buffers for disk and filesystem  and to improve overall disk 
			write performance.
		
		It is generally recommended that the per-node RAM quota does not exceed 80% of 
		the total RAM of the machine.
		</p>
		
		<p>How much memory and disk space per node you will need depends on several different
			variables.</p>
			
			
			<p>The following are per-bucket calculations and must be summed up across all buckets. If all the
			buckets have the same configuration, treat the total data as a single bucket. There is
			no per-bucket overhead that needs to be considered.</p>
			
		
			
			<p>For example, if you have 8GB machines and you want to use 6 GB for
				Couchbase…</p>
			
			<codeblock>number of nodes =
    Cluster RAM quota required/per_node_ram_quota =
    7.9 GB/6GB = 1.3 or 2 nodes
</codeblock>
			
			
		
	
		
		<section><title>Network bandwidth</title>
			<p>Network bandwidth is not normally a significant
				factor to consider for cluster sizing. However, clients require network bandwidth to
				access information in the cluster. Nodes also need network bandwidth to exchange
				information (node to node).</p>
			
			<p>In general, calculate your network bandwidth requirements using the following formula:</p>
			
			<codeblock>Bandwidth = (operations per second * item size) + overhead for rebalancing </codeblock>
			
			<p>Calculate the <codeph>operations per second</codeph> with the following formula:</p>
			
			<codeblock>Operations per second = Application reads + (Application writes * Replica copies) </codeblock>
			</section>
		
		<section><title>Data safety</title>
			<p>Make sure you have enough nodes (and the right
				configuration) in your cluster to keep your data safe. There are two areas to keep
				in mind: how you distribute data across nodes and how many replicas you store across
				your
				cluster.</p>
		</section>
		
		<section><title>Data distribution</title>
			<p>Basically, more nodes are better than less. If
				you only have two nodes, your data is split across the two nodes, half and half. 
				This means that half of your dataset is impacted if one goes away. 
				On the other hand, with ten nodes, only 10% of the dataset is impacted if one nodes goes away. 
				Even with automatic failover, there still is some period of time when data is unavailable if nodes fail. 
				This is mitigated by having more nodes.</p>
			
			<p>After a failover, the cluster takes on an extra load. The question is how heavy is that extra
				load and are you prepared for it? With only two nodes, each one needs to be ready to
				handle the entire load; with ten nodes, each node only needs to be able to take on
				an extra tenth of the workload should one fail.</p>
			
			<p>While two nodes provide a minimal level of redundancy, it is  recommended to always use at
				least three nodes.</p>
		</section>
		
		<section><title>Replication</title>
			<p>Couchbase Server authorizes you to configure up to three replicas (creating four copies of the
				dataset). In the event of a failure, you can only <term>fail over</term> (either
				manually or automatically) as many nodes as you have replicas. For example:</p>
			<ul>
				<li>In a five node cluster with one replica, if one node goes down, you can fail
						it over. If a second node goes down, you no longer have enough replica
						copies to fail over to and will have to go through a slower process to
						recover.</li>
				<li>In a five node cluster with two replicas, if one node goes down, you can fail
						it over. If a second node goes down, you can fail it over as well. Should a
						third one go down, you now no longer have replicas to fail over.</li>
			</ul>
			<p>After a node goes down and is failed over, try to replace that node as soon as possible and
				rebalance. Rebalancing recreates the replica copies (if you still have enough nodes
				to do so).</p>
			
			<note type="tip">As a rule of thumb, configure the following:
			<ul>
				<li>One replica for up to five nodes.</li>
				<li>One or two replicas for five to ten nodes.</li>
				<li>One, two, or three replicas for over ten nodes.</li>
			</ul>
				While there can be variations to this, there are diminishing returns from having more replicas in smaller clusters.
			</note>
			
			</section>
		
		<section><title>Hardware requirements</title>
			<p>In general, Couchbase Server has very low hardware requirements and is designed to be
				run on commodity or virtualized systems. However, as a rough guide to the primary
				concerns for your servers, the following is recommended: </p><dl>
				<dlentry>
					<dt>RAM</dt>
					<dd>This is your primary consideration. Couchbase Server uses RAM to store
						active items, and that is the key reason it has such low latency.</dd>
				</dlentry>
			</dl><dl>
				<dlentry>
					<dt>CPU</dt>
					<dd>Couchbase Server has very low CPU requirements. It is multi-threaded and,
						therefore, benefits from a multi-core system. Machines with at least four or
						eight physical cores are recommended.</dd>
				</dlentry>
			</dl><dl>
				<dlentry>
					<dt>Disk</dt>
					<dd>By decoupling the RAM from the I/O layer, Couchbase Server can support
						low-performance disks better than other databases. As a best practice, have
						separate devices for server install, data directories, and index
						directories.</dd>
				</dlentry>
			</dl><dl>
				<dlentry>
					<dt>Network</dt>
					<dd>Most configurations work with Gigabit Ethernet interfaces. Faster solutions
						such as 10GBit and Infiniband will provide spare capacity.</dd>
				</dlentry>
			</dl> Known working configurations include SAN, SAS, SATA, SSD, and EBS with the
			following recommendations:<ul>
				<li>SSDs have been shown to provide a great performance boost both in terms of
					draining the write queue and also in restoring data from disk (either on
					cold-boot or for purposes of rebalancing).</li>
				<li>RAID generally provides better throughput and reliability.</li>
				<li>Striping across EBS volumes (in Amazon EC2) has been shown to increase
					throughput.</li>
			</ul>
		</section>
		
		<section><title>Considerations for Cloud environments (that is Amazon EC2)</title>
			<p>Due to the unreliability and general lack of consistent I/O performance in cloud environments,
				it is highly recommended to lower the per-node RAM footprint and increase the number
				of nodes. This will give better disk throughput and improve rebalancing, since each
				node will have to store (and therefore transmit) less data. By distributing the data
				further, it lessens the impact of losing a single node, which could be fairly
				common.</p>
		</section>-->
	</body>

</topic>
