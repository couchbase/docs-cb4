<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE concept
PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept xml:lang="en-us" id="download">
	<title>Java API</title>
	<shortdesc>In addition to the primary Scala API, the connector provides convenience APIs when
		accessed from Java.</shortdesc>

	<conbody>

		<section>
			<title>Couchbase from the SparkContext</title>

			<p>To use the Java API in spark, you need to initialize a <codeph>JavaSparkContext</codeph>:</p>

<codeblock outputclass="language-java"><![CDATA[SparkConf conf = new SparkConf()
    .setAppName("javaSample")
    .setMaster("local[*]")
    .set("com.couchbase.bucket.travel-sample", "");

JavaSparkContext sc = new JavaSparkContext(conf);]]></codeblock>

		<p>Since Spark 2.0 you can also use the <codeph>SparkSession</codeph>:</p>

		<codeblock outputclass="language-java"><![CDATA[SparkSession spark = SparkSession
		.builder()
		.appName("JavaExample")
		.master("local[*]") // use the JVM as the master, great for testing
		.config("spark.couchbase.nodes", "127.0.0.1") // connect to couchbase on localhost
		.config("spark.couchbase.bucket.travel-sample", "") // open the travel-sample bucket with empty password
		.getOrCreate();

// The Java wrapper around the SparkContext
JavaSparkContext sc = new JavaSparkContext(spark.sparkContext());
			]]></codeblock>

    		<p>Since Java doesn't have the implicit imports like Scala, the connector provides a helper
				class to achieve similar functionality:</p>

<codeblock outputclass="language-java"><![CDATA[// The Couchbase-Enabled spark context
CouchbaseSparkContext csc = couchbaseContext(sc);]]></codeblock>

			<p>The context is a static import. In general you want to statically import the following:</p>

<codeblock outputclass="language-java"><![CDATA[import static com.couchbase.spark.japi.CouchbaseDocumentRDD.couchbaseDocumentRDD;
import static com.couchbase.spark.japi.CouchbaseSparkContext.couchbaseContext;]]></codeblock>

			<p>Now you can create RDDs through Key/Value, Views or N1QL:</p>

<codeblock outputclass="language-java"><![CDATA[// Load docs through K/V
List<JsonDocument> docs = csc
    .couchbaseGet(Arrays.asList("airline_10226", "airline_10748"))
    .collect();

System.out.println(docs);]]></codeblock>


<codeblock outputclass="language-java"><![CDATA[// Perform a N1QL query
List<CouchbaseQueryRow> results = csc
    .couchbaseQuery(N1qlQuery.simple("SELECT * FROM `travel-sample` LIMIT 10"))
    .collect();

System.out.println(results);]]></codeblock>

	</section>

	<section>
		<title>Mapping RDDs to Couchbase APIs</title>

		<p>An RDD can be wrapped with the <codeph>couchbaseRDD</codeph> static method to expose all the
				functions available. So instead of fetching the documents right from the
					<codeph>SparkContext</codeph> it can also be done like this:</p>

		<codeblock outputclass="language-java"><![CDATA[import static com.couchbase.spark.japi.CouchbaseRDD.couchbaseRDD;
//...
JavaRDD<String> ids = sc.parallelize(Arrays.asList("airline_10226", "airline_10748"));
docs = couchbaseRDD(ids).couchbaseGet().collect();
System.out.println(docs);]]></codeblock>

		<p>The <codeph>CouchbaseRDD</codeph> exposes the following methods:</p>

		<ul>
			<li><codeph>couchbaseGet</codeph>: Fetch documents via their unique Document ID.</li>
			<li><codeph>couchbaseSubdocLookup</codeph>: Fetch fragments of a document.</li>
			<li><codeph>couchbaseView</codeph>: Query a Couchbase View.</li>
			<li><codeph>couchbaseSpatialView</codeph>: Query a Couchbase Spatial View.</li>
			<li><codeph>couchbaseQuery</codeph>: Perform a N1QL Query.</li>
		</ul>

	</section>

	<section>
		<title>Using SparkSQL with Couchbase from Java</title>

		<p>Using SparkSQL from Java is possible because the Java API provides wrappers for both the <codeph>DataFrameReader</codeph>
		and <codeph>DataFrameWriter</codeph> APIs. All you need to do is wrap the ones that are returned by Spark and wrap them
		like in the following example to get access to all couchbase specific methods:</p>

<codeblock outputclass="language-java"><![CDATA[import static com.couchbase.spark.japi.CouchbaseDataFrameReader.couchbaseReader;
//...

// Use SparkSQL from Java
SQLContext sql = new SQLContext(sc);

// Wrap the Reader and create the DataFrame from Couchbase
Dataset<Row> airlines = couchbaseReader(sql.read()).couchbase(new EqualTo("type", "airline"));

// Print the number of airline
System.out.println("Number of Airlines: " + airlines.count());]]></codeblock>

	</section>

	<section>
		<title>Using Datasets with Couchbase</title>

		<p>Since Datasets work with actual Java objects, first create one:</p>

<codeblock outputclass="language-java"><![CDATA[import java.io.Serializable;

public class Airport implements Serializable {
    private String name;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }
}]]></codeblock>

	<p>Next, you can convert a <codeph>DataFrame</codeph> to a <codeph>Dataset</codeph> through the <codeph>.as()</codeph>
	API in Spark 1.6:</p>

<codeblock outputclass="language-java"><![CDATA[Dataset<Airport> airports = couchbaseReader(sql.read())
	.couchbase(new EqualTo("type", "airport"))
	.select(new Column("airportname").as("name"))
	.as(Encoders.bean(Airport.class));

	List<Airport> allAirports = airports.collectAsList();
	System.out.println(allAirports.size());]]></codeblock>

	</section>

	<section>
		<title>Writing to Couchbase</title>

		<p>If you want to store Documents in Couchbase, use the <codeph>couchbaseDocumentRDD</codeph>
				method:</p>

<codeblock outputclass="language-java"><![CDATA[couchbaseDocumentRDD(
    sc.parallelize(Arrays.asList(JsonDocument.create("doc1", JsonObject.empty())))
).saveToCouchbase();]]></codeblock>

		</section>
	</conbody>
</concept>
