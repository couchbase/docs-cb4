<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="cbepctl-threadpool-tuning">
  <title><cmdname>set flush_param</cmdname></title>
  <shortdesc>The command <cmdname>set flush_param</cmdname> tunes the dynamic shared thread pool
    performance.</shortdesc>
  <refbody>
    <section><title>Syntax</title>
      <p>The basic syntax is:</p>
      <codeblock>cbepctl [host]:11210 -b [bucket-name] set flush_param [parameter] [value]</codeblock>
  
  
  
      <p>The syntax to configure the access log settings is: </p>
      <codeblock>cbepctl [hostname]:11210 -b [bucket-name] -p [bucket-password] set flush_param alog_sleep_time [value]
cbepctl [hostname]:11210 -b [bucket-name] -p [bucket-password] set flush_param alog_task_time [value]</codeblock>
   

      <p>The syntax for disk cleanup is:</p>
      <codeblock>cbepctl [host]:11210 -b [bucket-name] -p [bucket-password] 
set flush_param exp_pager_stime [value]</codeblock>
      
      
      
   <p>The syntax for ejection is:</p>
      <codeblock>cbepctl [host]:11210 -b [bucket-name] -p [bucket-password] 
set flush_param [parameter] [value]</codeblock>
      
      <p>Parameters used for changing ejection thresholds:</p>
      <ul>
        <li><codeph>mem_low_wat</codeph></li>
        <li><codeph>mem_high_wat</codeph></li>
        <li><codeph>pager_active_vb_pcnt</codeph></li>
      </ul>
      
      <p>The syntax to set the out of memory threshold is:</p>
      <codeblock>cbepctl [host]:11210 -b [bucket-name] -p [bucket-password] 
set flush_param mutation_mem_threshold [value]</codeblock>
     
      
      
    </section>
    <section><title>Description</title>
      <p>Tune the dynamic shared thread pool performance by changing the thread types inside the
        ep-engine and memcached at run time. The command <cmdname>set flush_param</cmdname> adjusts
        the number of threads that prioritize read, write, non-i/o and auxiliary-i/o operations.
        These settings take effect immediately and do not require that the bucket be restarted. </p>
        
      <note type="note">The settings for threads number take effect only if the underlying operating
        system has a sufficient number of CPU cores. The minimum number of CPU cores is four (4),
        but  three (3) additional cores are required for each additional writer thread. For example,
        five (5) writer threads is a valid setting if the underlying hardware has at least sixteen
        (16) cores.</note>
      <note type="note">Changes of thresholds are NOT persistent and must be reapplied after the
        bucket warmup.</note>
      
   <dl>
     <dlentry>
       <dt>alog_sleep_time, alog_task_time</dt>
       <dd>Couchbase Server has an optimized <xref
         href="../../understanding-couchbase/buckets-memory-and-storage/memory.dita#memory/initialization-and-warmup">disk
              warmup</xref>. Couchbase Server pre-fetches a list of most-frequently accessed keys
            and fetches these documents first. The server runs a periodic scanner process which
            determines which keys are most frequently used. The <codeph>cbepctl flush_param</codeph>
            command is used to change the initial time and the interval for the process. For
            example, the initial time and interval might be changed to accommodate a peak time when
            an application needs these keys to be quickly available. <p>By default, the scanner
              process runs once every 24 hours at 10:00 AM GMT. To reduce the cluster-wide impact of
              running this task, stagger the start time to a different value on each node in the
              cluster.</p></dd>
     </dlentry>
   </dl> 
    
    
    <dl>
      <dlentry>
        <dt>exp_pager_stime</dt>
        <dd>The <codeph>cbepctl flush_param exp_pager_stime</codeph> command sets the time interval
            for disk cleanup. Couchbase Server does lazy <xref
              href="../../understanding-couchbase/buckets-memory-and-storage/memory.dita#memory/expiry-pager">expiration</xref>, that
            is, expired items are flagged as deleted rather than being immediately erased. Couchbase
            Server has a maintenance process that periodically looks through all information and
            erases expired items. By default, this maintenance process runs every 60 minutes, but it
            can be configured to run at a different interval.
          <note type="note">The compaction process will also remove expired items.</note></dd>
      </dlentry>
    </dl>
  

<dl>
  <dlentry>
    <dt>mem_low_wat, mem_high_wat, pager_active_vb_pcnt</dt>
    <dd><xref href="../../understanding-couchbase/buckets-memory-and-storage/memory.dita#memory/ejection"
              >Ejection</xref> means that documents are removed from RAM but the key and metadata
            remain. If the amount of RAM used by items reaches the high water mark (upper
            threshold), both active and replica data are ejected until the memory usage (amount of
            RAM consumed) reaches the low water mark (lower threshold). The server determines that
            items are not recently used based on a not-recently-used (NRU) value. <p>Use the
                <codeph>mem_low_wat</codeph>, <codeph>mem_high_wat</codeph>, and
                <codeph>pager_active_vb_pcnt</codeph> settings to change the server thresholds for
              ejection. </p><note type="warning">Do not change the ejection defaults unless required
              by Couchbase Support.</note></dd>
  </dlentry>
</dl>
  
  
  <dl>
    <dlentry>
      <dt>mutation_mem_threshold]</dt>
      <dd>By default, Couchbase Server sends clients a temporary out-of-memory error message if RAM
            is 95% consumed and only 5% RAM remains for overhead. Use the <codeph>cbepctl set
              flush_param mutation_mem-threshold</codeph> command parameter to change this threshold
            value. <note type="note">Do not change this default to a higher value. However, this
              value might be reduced if you need more RAM for system overhead such as disk queue or
              for server data structures.</note></dd>
    </dlentry>
  </dl>
    </section>
    
    <section><title>Options</title>
      
      <p>The following are the command options:</p>
      <table><title>set flush_param options</title>
        <tgroup cols="2">
          <colspec colname="col1" colwidth="3*"/>
          <colspec colname="col2" colwidth="3*"/>
          <thead>
            <row>
              <entry>Option</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry><codeph>alog_sleep_time</codeph></entry>
              <entry>Access scanner interval (minute)</entry>
            </row>
            <row>
              <entry><codeph>alog_task_time</codeph></entry>
              <entry>Access scanner next task time (UTC)</entry>
            </row>
            <row>
              <entry><codeph>backfile_mem_threshold</codeph></entry>
              <entry>Memory threshold (%) on the current bucket quota before backfill task is made
                to back off.</entry>
            </row>
            <row>
              <entry><codeph>bg_fetch_delay</codeph></entry>
              <entry>Delay before executing a bg fetch (test feature).</entry>
            </row>
            <row>
              <entry><codeph>couch_response_timeout</codeph></entry>
              <entry>timeout in receiving a response from CouchDB.</entry>
            </row>
            <row>
              <entry><codeph>exp_pager_stime</codeph></entry>
              <entry>Expiry Pager interval. Time interval that Couchbase Server waits before it
                performs cleanup and removal of expired items from disk. Setting this value to
                  <codeph>0</codeph> will disable the Expiry Pager from running.</entry>
            </row>
            <row>
              <entry><codeph>flushall_enabled</codeph></entry>
              <entry>Deprecated. Enable flush operation.</entry>
            </row>
            <row>
              <entry><codeph>pager_active_vb_pcnt</codeph></entry>
              <entry>Percentage of active vBuckets items among all ejected items by item
                pager.</entry>
            </row>
            <row>
              <entry><codeph>max_size</codeph></entry>
              <entry>Maximum memory used by the server.</entry>
            </row>
            <row>
              <entry><codeph>mem_high_wat</codeph></entry>
              <entry>High water mark in bytes.</entry>
            </row>
            <row>
              <entry><codeph>mem_low_wat</codeph></entry>
              <entry>Low water mark in bytes.</entry>
            </row>
            <row>
              <entry><codeph>mutation_mem_threshold</codeph></entry>
              <entry>Amount of RAM that can be consumed in that caching layer before clients start
                receiving temporary out of memory messages.</entry>
            </row>
            <row>
              <entry><codeph>timing_log</codeph></entry>
              <entry>Path to log detailed timing stats. </entry>
            </row>
            <row>
              <entry><codeph>warmup_min_memory_threshold</codeph></entry>
              <entry>Memory threshold (%) during warmup to enable traffic.</entry>
            </row>
            <row>
              <entry><codeph>warmup_min_items_threshold</codeph></entry>
              <entry>Item number threshold (%) during warmup to enable traffic.</entry>
            </row>
            <row>
              <entry><codeph>klog_compactor_queue_cap</codeph></entry>
              <entry>Queue cap to throttle the log compactor.</entry>
            </row>
            <row>
              <entry><codeph>klog_max_log_size</codeph></entry>
              <entry>Maximum size of a mutation log file allowed.</entry>
            </row>
            <row>
              <entry><codeph>klog_max_entry_ratio</codeph></entry>
              <entry>Max ratio of # of items logged to # of unique items.</entry>
            </row>
            <row>
              <entry><codeph>pager_unbiased_period</codeph></entry>
              <entry>Period after last access scanner run during which item pager preserve working
                set.</entry>
            </row>
            <row>
              <entry><codeph>queue_age_cap</codeph></entry>
              <entry>Maximum queue age before flushing data.</entry>
            </row>
            <row>
              <entry><codeph>max_txn_size</codeph></entry>
              <entry>Maximum number of items in a flusher transaction.</entry>
            </row>
            <row>
              <entry><codeph>min_data_age</codeph></entry>
              <entry>Minimum data age before flushing data.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      
      <note type="note"><b>%</b> You must use the percentage sign in order to set the value by
        percentage.</note>
    </section>
    <section><title>Performance tuning options</title>
      <p>The following are the command options used for performance tuning. </p>
      <p>All these options can be used only to tune down the number of threads: if the value was set
        as N at initial startup, then only a value &lt; N will work.</p>
      <table>
        
        <tgroup cols="2">
          <colspec colname="col1" colwidth="3*"/>
          <colspec colname="col2" colwidth="3*"/>
          <thead>
            <row>
              <entry>Option</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry><codeph>max_num_readers</codeph></entry>
              <entry>Overrides the default number of global threads that prioritize read
                operations.</entry>
            </row>
            <row>
              <entry><codeph>max_num_writers</codeph></entry>
              <entry>Overrides the default number of global threads that prioritize write
                operations.</entry>
            </row>
            <row>
              <entry><codeph>max_num_auxio</codeph></entry>
              <entry>Overrides the default number of global threads that prioritize auxio
                operations.</entry>
            </row>
            <row>
              <entry><codeph>max_num_nonio</codeph></entry>
              <entry>Overrides the default number of global threads that prioritize nonio
                operations.</entry>
            </row>
          </tbody>
        </tgroup>
      </table> 
    </section>
    
    
    
    <section><title>Examples </title><p><b>Examples for setting the maximum number of
        writers:</b></p><p><b>Number of writers</b>
      </p><p>To set the maximum number of writers, use <codeph>max_num_writers</codeph> parameter.
        </p><p>In the following example, <codeph>max_num_writers</codeph> sets the number of writer
        threads to four (4).  The command can both increase and decrease the writer threads.
        However, the increase is capped to the limit set when the bucket warms up. If you start the
        bucket with four writer threads, you can dynamically reduce to a lower value such as two and
        then later dynamically increase back to four, but increasing above four will have no
        effect.</p><codeblock>cbepctl 10.5.2.117:11210 -b foo_bucket set flush_param max_num_writers 4 </codeblock><p>The
        following is an example response when setting the maximum number of writer
          threads.</p><codeblock>setting param: max_num_writers 4
set max_num_writers to 4    </codeblock><p><b>Number
          of threads</b></p><p>Check how many threads of various types are currently running by
        using <codeph>cbstats workload</codeph>. For
        example:</p><codeblock>cbstats [host]:11210 -b [bucket-name] workload  </codeblock><p>For
        example, the following shows an example request and response for <codeph>cbstats
          workload</codeph>, in this case, for the default bucket. The setting change,
          <codeph>ep_workload:max_writers: 5</codeph>, is displayed via the <codeph>cbstats
          workload</codeph> response: </p><codeblock>cbstats 10.5.2.117:11210 workload

 ep_workload:LowPrioQ_AuxIO:InQsize:   2
 ep_workload:LowPrioQ_AuxIO:OutQsize:  0
 ep_workload:LowPrioQ_NonIO:InQsize:   18
 ep_workload:LowPrioQ_NonIO:OutQsize:  0
 ep_workload:LowPrioQ_Reader:InQsize:  8
 ep_workload:LowPrioQ_Reader:OutQsize: 0
 ep_workload:LowPrioQ_Writer:InQsize:  12
 ep_workload:LowPrioQ_Writer:OutQsize: 0
 ep_workload:max_auxio:                1
 ep_workload:max_nonio:                1
 ep_workload:max_readers:              4
 ep_workload:max_writers:              5
 ep_workload:num_auxio:                1
 ep_workload:num_nonio:                1
 ep_workload:num_readers:              4
 ep_workload:num_shards:               4
 ep_workload:num_sleepers:             10
 ep_workload:num_writers:              5
 ep_workload:ready_tasks:              0
       </codeblock><sectiondiv><p>
          <b>Examples for setting the access scanner process</b></p><p>To change the time interval
          when the access scanner process runs to every 20
          minutes.</p><codeblock>cbepctl 10.5.2.117:11210 -b foo-bucket -p foo-password \ 
set flush_param alog_sleep_time 20</codeblock><p>To
          change the initial time that the access scanner process runs from the 2:00 AM UTC default
          to 11:00 PM
        UTC.</p><codeblock>cbepctl 10.5.2.117:11210 foo-bucket -p foo-password \ 
set flush_param alog_task_time 23</codeblock>This
        response shows the time interval changed to 20 minutes.
          <codeblock>setting param: alog_sleep_time 20 
set alog_sleep_time to 20      </codeblock><p>This
          response shows the initial access scanner run time changed to 11:00 PM
        UTC.</p><codeblock>setting param: alog_task_time 23 
set alog_task_time to 23      </codeblock></sectiondiv><p><b>Examples
          for setting the disk cleanup</b></p><p>The following example sets the cleanup process to
        run every 600 seconds (10 minutes). This is the interval that Couchbase Server waits before
        it tries to remove expired items from
        disk.</p><codeblock>cbepctl 10.5.2.117:11210 -b mybucket -p password \
set flush_param exp_pager_stime 600</codeblock><p>The
        following example response shows the cleanup process set to 600 seconds.</p><codeblock>setting param: exp_pager_stime 600
set exp_pager_stime to 600      </codeblock><sectiondiv>
        <p><b>Examples for setting the out-of-memory error message</b>
        </p>
        <p>In this example, the threshold is reduced to 65% of RAM. </p>
        <codeblock>cbepctl 10.5.2.117:11210 -b foo-bucket -p foo-password \
set flush_param mutation_mem_threshold 65%</codeblock>
        <p>The following example response shows the RAM threshold set to 65%. </p>
        <codeblock>setting param: mutation_mem_threshold 65
set mutation_mem_threshold to 65      </codeblock>
      </sectiondiv><p><b>Example for setting the low water mark</b>
      </p><p>The low water mark sets the lower threshold of RAM for a specific bucket on a node. The
        item pager stops ejecting items once the low water mark is reached. </p><p>The following
        example sets the low water mark percentage to 70% of
          RAM.</p><codeblock>cbepctl 10.5.2.117:11210 -b foo-bucket -p foo-password \
set flush_param mem_low_wat 70%</codeblock><p><b>Example
          for setting the high water mark</b>
      </p><p>The high water mark set the amount of RAM consumed by items that must be breached
        before infrequently used active and replica items are ejected.</p><p>The following example
        sets the high water mark percentage to 80% of RAM for a specific bucket on a node. This
        means that items in RAM on this node can consume up to 80% of RAM before the item pager
        begins ejecting items.
          </p><codeblock>cbepctl 10.5.2.117:11210 -b foo-bucket -p foo-password \
set flush_param mem_high_wat 80%</codeblock><p><b>Examples
          for setting percentage of ejected items</b></p><p>Based on the NRU algorithm, the server
        ejects active and replica data from a node. By default, the server is configured to 60%
        active items and 40% replica data from a node.</p><p>The following example increases the
        percentage of active items that can be ejected from a node to
      50%.</p><codeblock>cbepctl 10.5.2.117:11210 -b foo-bucket -p foo-password \
set flush_param pager_active_vb_pcnt 50</codeblock>Be
      aware of potential performance implications when changing the percentage of ejected items. It
      may be more desirable to eject as many replica items as possible and limit the amount of
      active data that can be ejected. By doing so, active data from a source node is maximized
      while maintaining incoming requests to that node. However, if the server is ejecting a very
      large percentage of replica data and a node fails, the replica data is not immediately
      available. In this case, the items are retrieved from disk and put back into RAM before the
      request is fulfilled. <p>The following example response shows the low water mark, high water
        mark, and percentage of ejected items being
      set.</p><codeblock>setting param: mem_low_wat 70
set mem_low_wat to 70

setting param: mem_high_wat 80
set mem_high_wat to 80

setting param: pager_active_vb_pcnt 50
set pager_active_vb_pcnt to 50     </codeblock>
    </section> 
  </refbody>
</reference>
