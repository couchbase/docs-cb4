<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference xml:lang="en-us" id="cbtransfer-tool">
	<title><cmdname>cbtransfer</cmdname>
	</title>
	<shortdesc>Transfers data between clusters or from files. </shortdesc>
	<refbody>
		<section><title>Syntax</title>
			<p>The basic syntax is:</p>
			<codeblock>cbtransfer [options] source destination</codeblock>
			
			
			<p>The following are syntax examples:</p>
			
			<codeblock>cbtransfer http://SOURCE:8091 /backups/backup-42
cbtransfer /backups/backup-42 http://DEST:8091
cbtransfer /backups/backup-42 couchbase://DEST:8091
cbtransfer http://SOURCE:8091 http://DEST:8091
cbtransfer file.csv http://DEST:8091			</codeblock>
		</section>
			<section>
			<title>Description</title> <p>The <cmdname>cbtransfer</cmdname> tool is the underlying,
			generic data transfer tool upon which <cmdname>cbbackup</cmdname> and
				<cmdname>cbrestore</cmdname> are built. </p> <p>It is a lightweight extract-transform-load (ETL) tool that transfers data between clusters and
				to and from files. The source and destination parameters are similar to URLs or file
				paths.</p> <p>The <cmdname>cbtransfer</cmdname> tool makes snap-shots of memory
				at the time it is invoked. All keys that are extracted pertain to the snapshot and
				not to the data that is added, edited or deleted while <cmdname>cbtransfer</cmdname>
				is running. </p>
			<note type="note">The most important way to use this tool is for transferring data from
				a Couchbase Server node that is no longer running to a cluster that is running. The
					<codeph>cbbackup</codeph>, <codeph>cbrestore</codeph>, and
					<codeph>cbtransfer</codeph> tools do not communicate with external IP addresses
				for server nodes outside of a cluster. Backup, restore, or transfer operations are
				performed on data from a node within a Couchbase Server cluster. They only communicate with
				nodes from a node list obtained within a cluster. If you install Couchbase Server
				with a default IP address, you cannot use an external hostname to access it.</note>
			<note type="note">Couchbase Server does not transfer design documents. To back up a
				design document, use <codeph>cbbackup</codeph> to store the information and
					<codeph>cbrestore</codeph> to read it back into memory.</note>
			<p>The tool is at the following location:</p>
			<table>
				<tgroup cols="2">
					<colspec colname="col1" colwidth="1*"/>
					<colspec colname="col2" colwidth="3*"/>
					<thead>
						<row>
							<entry>Operating system</entry>
							<entry>Location</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry>Linux</entry>
							<entry><filepath>/opt/couchbase/bin/</filepath></entry>
						</row>
						<row>
							<entry>Windows</entry>
							<entry><filepath>C:\Program Files\Couchbase\Server\bin\</filepath></entry>
						</row>
						<row>
							<entry>Mac OS X</entry>
							<entry><filepath>/Applications/Couchbase Server.app/Contents/Resources/couchbase-core/bin/</filepath></entry>
						</row>
					</tbody>
				</tgroup>
			</table>
		</section>
		
		<section><title>Options</title>
			<p>The following are the command options:</p>
		<table>
			<title>cbtransfer options</title>
			<tgroup cols="2">
					<colspec colname="col1" colwidth="1*"/>
					<colspec colname="col2" colwidth="1.45*"/>
					<thead>
						<row>
							<entry>Parameters</entry>
							<entry>Description</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><codeph>-h, --help</codeph></entry>
							<entry>Command line HELP.</entry>
						</row>
						<row>
							<entry><codeph>-b BUCKET_SOURCE</codeph></entry>
							<entry>Single named bucket from a source cluster to transfer.</entry>
						</row>
						<row>
							<entry><codeph>-B BUCKET_DESTINATION</codeph>,
									<codeph>--bucket-destination=BUCKET_DESTINATION</codeph></entry>
							<entry>Single named bucket on the destination cluster that receives the
								transfer. You can transfer to a bucket with a different name than
								your source bucket; if you do not provide a name, it defaults to the
								same name as the bucket-source.</entry>
						</row>
						<row>
							<entry><codeph>-i ID</codeph>, <codeph>--id=ID</codeph></entry>
							<entry>Transfer only items that match the vbucket ID.</entry>
						</row>
						<row>
							<entry><codeph>-k KEY</codeph>, <codeph>--key=KEY</codeph></entry>
							<entry>Transfer only items with keys that match the
									<codeph>regexp</codeph>. <sup>1</sup></entry>
						</row>
						<row>
							<entry><codeph>-n</codeph>, <codeph>--dry-run</codeph></entry>
							<entry>No actual transfer occurs, just the validation of parameters,
								files, connectivity, and configurations.</entry>
						</row>
						<row>
							<entry><codeph>-u USERNAME</codeph>,
									<codeph>--username=USERNAME</codeph></entry>
							<entry>REST username for the source cluster or the server node.</entry>
						</row>
						<row>
							<entry><codeph>-p PASSWORD</codeph>,
									<codeph>--password=PASSWORD</codeph></entry>
							<entry>REST password for the cluster or the server node.</entry>
						</row>
						<row>
							<entry><codeph>-t THREADS</codeph>,
								<codeph>--threads=THREADS</codeph></entry>
							<entry>Number of concurrent worker threads performing the transfer.
								Memcached uses 75% of the number of cores reported of the system
								(with a minimum of 4 cores) <sup>2</sup>.</entry>
						</row>
						<row>
							<entry><codeph>-v</codeph>, <codeph>--verbose</codeph></entry>
							<entry>Verbose logging; provide more verbosity.</entry>
						</row>
						<row>
							<entry><codeph>-x EXTRA</codeph>, <codeph>--extra=EXTRA</codeph></entry>
							<entry>Provide extra, uncommon configuration parameters.</entry>
						</row>
						<row>
							<entry><codeph>--single-node</codeph></entry>
							<entry>Transfer from a single server node in a source cluster. This
								single server node is a source node URL.</entry>
						</row>
						<row>
							<entry><codeph>--source-vbucket-state=SOURCE_VBUCKET_STATE</codeph></entry>
							<entry>Only transfer from the source vbuckets occurs in this state, such
								as <codeph>active</codeph> (default) or <codeph>replica</codeph>.
								Must be used with the Couchbase cluster as a source.</entry>
						</row>
						<row>
							<entry><codeph>--destination-vbucket-state=DESTINATION_VBUCKET_STATE</codeph></entry>
							<entry>Only transfer to destination vbuckets in this state, such as
									<codeph>active</codeph> (default) or <codeph>replica</codeph>.
								Must be used with Couchbase Server Server cluster as the
								destination.</entry>
						</row>
						<row>
							<entry><codeph>--destination-operation=DESTINATION_OPERATION</codeph></entry>
							<entry>Perform this operation on transfer. <cmdname>set</cmdname> will
								override an existing document;<cmdname>add</cmdname> will not
								override; <cmdname>get</cmdname> will load all keys transferred from
								a source cluster into the caching layer at the destination. <note
									type="important">By default, the <codeph>cbtransfer</codeph>
									tool will use <cmdname>set</cmdname> and override any existing
									documents.</note></entry>
						</row>
						<row>
							<entry><codeph><filepath>/path/to/filename</filepath></codeph></entry>
							<entry>Export a <codeph>.csv </codeph>file from the server or import a
									<codeph>.csv</codeph> file to the server. </entry>
						</row>
					</tbody>
				</tgroup>
		</table>
			
			<p><sup>1</sup>: Regex (Regular Expression Syntax) specifies a set of strings that matches it; the
				functions in this module let you check if a particular string matches a given
				regular expression (or if a given regular expression matches a particular string,
				which comes down to the same thing). For a complete reference, see <xref
					href="https://docs.python.org/2/library/re.html" format="html" scope="external"
				/>.</p>
			
			<p><sup>2</sup>: To tune memcached to adjust dynamically the number of worker threads, do one of
				the following: <ul>
					<li>Export <codeph>MEMCACHED_NUM_CPUS=number</codeph> of threads you want before
						starting Couchbase Server.</li>
					<li>Use the <codeph>-t </codeph>&lt;number &gt; command line argument.</li>
					<li>Specify it in the configuration file that is read during startup. Be aware
						that when started from the full server this file is regenerated every time,
						and you will loose the modifications.</li>
				</ul>
			</p>
			
			
			<p>The following are extra, specialized command options with the <codeph>cbtransfer -x</codeph>
				parameter.</p>
			
			<table>
				<title>cbtransfer -x options</title>
			<tgroup cols="2">
					<colspec colname="col1" colwidth="2*"/>
					<colspec colname="col2" colwidth="3*"/>
					<thead>
						<row>
							<entry><codeph>-x options</codeph></entry>
							<entry>Description</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><codeph>backoff_cap=10</codeph></entry>
							<entry>Maximum backoff time during the rebalance period.</entry>
						</row>
						<row>
							<entry><codeph>batch_max_bytes=400000</codeph></entry>
							<entry>Transfer this # of bytes per batch.</entry>
						</row>
						<row>
							<entry><codeph>batch_max_size=1000</codeph></entry>
							<entry>Transfer this # of documents per batch.</entry>
						</row>
						<row>
							<entry><codeph>cbb_max_mb=100000</codeph></entry>
							<entry>Split backup file on destination cluster if it exceeds the
								MB.</entry>
						</row>
						<row>
							<entry><codeph>conflict_resolve=1</codeph></entry>
							<entry>By default, disable conflict resolution.</entry>
						</row>
						<row>
							<entry><codeph>data_only=0</codeph></entry>
							<entry>For value 1, transfer only data from a backup file or
								cluster.</entry>
						</row>
						<row>
							<entry><codeph>design_doc_only=0</codeph></entry>
							<entry>For value 1, transfer only design documents from a backup file or
								cluster. Default: 0.</entry>
						</row>
						<row>
							<entry><codeph>max_retry=10</codeph></entry>
							<entry>Max number of sequential retries if the transfer fails.</entry>
						</row>
						<row>
							<entry><codeph>mcd_compatible=1</codeph></entry>
							<entry>For value 0, display extended fields for stdout output.</entry>
						</row>
						<row>
							<entry><codeph>nmv_retry=1</codeph></entry>
							<entry>0 or 1, where 1 retries transfer after a NOT_MY_VBUCKET message.
								Default: 1.</entry>
						</row>
						<row>
							<entry><codeph>recv_min_bytes=4096</codeph></entry>
							<entry>Amount of bytes for every TCP/IP batch transferred.</entry>
						</row>
						<row>
							<entry><codeph>rehash=0</codeph></entry>
							<entry>For value 1, rehash the partition IDs of each item. Rehashing is required when
								transferring data between clusters with a different number of
								partitions, such as when transferring data from a Mac OSX server to
								a non-Mac OSX cluster.</entry>
						</row>
						<row>
							<entry><codeph>report=5</codeph></entry>
							<entry>Number of batches transferred before updating the progress bar in the console.</entry>
						</row>
						<row>
							<entry><codeph>report_full=2000</codeph></entry>
							<entry>Number of batches transferred before emitting progress
								information in the console.</entry>
						</row>
						<row>
							<entry><codeph>seqno=0</codeph></entry>
							<entry>By default, start <codeph>seqno</codeph> from beginning.</entry>
						</row>
						<row>
							<entry><codeph>try_xwm=1</codeph></entry>
							<entry>Transfer documents with metadata. Default: 1. The value of <codeph>0</codeph> is  used
								only when transferring from 1.8.x to 1.8.x.</entry>
						</row>
						<row>
							<entry><codeph>uncompress=0</codeph></entry>
							<entry>For value 1, restore data in the uncompressed mode.</entry>
						</row>
					</tbody>
				</tgroup>
		</table>
		</section>
		
		
		
		
		<section><title>Examples</title>
		<p><b>Example for transferring data between nodes:</b></p>
			<p>To transfer data from a non-running node to a running cluster:</p>
			<codeblock>cbtransfer
	couchstore-files://COUCHSTORE_BUCKET_DIR
	couchbase://HOST:PORT
	--bucket-destination=DESTINATION_BUCKET			</codeblock>
       

<codeblock>cbtransfer
	couchstore-files:///opt/couchbase/var/lib/couchbase/data/default
	couchbase://10.5.3.121:8091
	--bucket-destination=foo</codeblock>
		
			<p>The response shows 10000 total documents transferred in batch size of 1088 documents each.</p>
		<codeblock>[####################] 100.0% (10000/10000 msgs)
bucket: bucket_name, msgs transferred...
      : total | last | per sec
batch : 1088 | 1088 | 554.8
byte : 5783385 | 5783385 | 3502156.4
msg : 10000 | 10000 | 5230.9
done</codeblock>
		<p><b>Example for sending data to the standard output:</b></p>
			<p>To send all the data from a node to the standard output:</p>
		<codeblock>cbtransfer http://10.5.2.37:8091/ stdout:

set pymc40 0 0 10
0000000000
set pymc16 0 0 10
0000000000
set pymc9 0 0 10
0000000000
set pymc53 0 0 10
0000000000
set pymc34 0 0 10
0000000000
</codeblock>
		
		
		
		
	<p>
				<b>Example for importing/exporting <codeph>csv</codeph> files:</b></p>
		<p>The <codeph>cbtransfer</codeph> tool is also used to import and export <codeph>csv</codeph>
				files. Data is imported into Couchbase Server as documents and documents are
				exported from the server into comma-separated values. Design documents associated
				with vBuckets are not included.</p>
			<p>In these examples, the following records are in the default bucket where re-fdeea652a89ec3e9
				is the document ID, 0 are flags, 0 is the expiration, and the CAS value is
				4271152681275955. The actual value is the hash starting with "{""key""....... </p>
		<codeblock>re-fdeea652a89ec3e9,
0,
0,
4271152681275955,
"{""key"":""re-fdeea652a89ec3e9"",
 ""key_num"":4112,
 ""name"":""fdee c3e"",
 ""email"":""fdee@ea.com"",
 ""city"":""a65"",
 ""country"":""2a"",
 ""realm"":""89"",
 ""coins"":650.06,
 ""category"":1,
 ""achievements"":[77, 149, 239, 37, 76],""body"":""xc4ca4238a0b923820d
 .......
""}"
......
</codeblock>
			<p>This example exports these items to a .csv file. All items are transferred from the default
				bucket, <codeph>-b default</codeph> available at the node
				<codeph>http://host:8091</codeph> and put into the
					<codeph>/data.csv</codeph> file. If a different bucket is provided for the
					<codeph>-b</codeph> option, all items are exported from that bucket. Credentials
				are required for the cluster when exporting items from a bucket in the cluster. </p>
			<codeblock>cbtransfer http://[host]:8091 csv:./data.csv -b default -u Administrator -p password
</codeblock>
		
			<p>The following example response is similar to that in other <codeph>cbtransfer</codeph>
				scenarios:</p>
		<codeblock>[####################] 100.0% (10000/10000 msgs)
bucket: default, msgs transferred...
       : total | last | per sec
 batch : 1053 | 1053 | 550.8
 byte : 4783385 | 4783385 | 2502156.4
 msg : 10000 | 10000 | 5230.9
2013-05-08 23:26:45,107: mt warning: cannot save bucket design on a CSV destination
done
</codeblock>
		<p>The following example syntax shows 1053 batches of data transferred at 550.8 batches per
				second. The tool outputs "cannot save bucket design…." to indicate that no design
				documents were exported. To import information from a.csv file to a named bucket in
				a cluster:</p>
		<codeblock>cbtransfer /data.csv http://[hostname]:[port] -B bucket_name -u Administrator -p password
</codeblock>
		<p>If the .csv file is not correctly formatted, the following error displays during import:</p>
		<codeblock>w0 error: fails to read from csv file, .....
</codeblock>
			
		</section>
		
		
	</refbody>
</reference>
