<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_rwk_h3v_xv">
    <title>Client Settings for the Java SDK with Couchbase Server</title>
    <titlealts><navtitle>Client Settings</navtitle></titlealts>
	<shortdesc>The <codeph>CouchbaseEnvironment</codeph> class enables you to configure Java SDK
		options for bootstrapping, timeouts, reliability, and performance.</shortdesc>

<body>
<section>
<title>The Environment Builder</title>

<p>Because <codeph>CouchbaseEnvironment</codeph> is an immutable class, you need to configure it
				by using its embedded <codeph>Builder</codeph> class. It is designed to apply the
				builder arguments in a fluent fashion and then create the
					<codeph>CouchbaseEnvironment</codeph> at the very end:</p>

<codeblock outputclass="language-java"><![CDATA[CouchbaseEnvironment env = DefaultCouchbaseEnvironment
    .builder()
    .mutationTokenEnabled(true)
    .computationPoolSize(5)
    .build();
Cluster cluster = CouchbaseCluster.create(env, "localhost");]]></codeblock>

<p>Alternatively, most options are tunable through system properties as well. If a system property is set, it always takes precedence over the builder setting:</p>

<codeblock outputclass="language-java"><![CDATA[System.setProperty("com.couchbase.kvEndpoints", "3");
CouchbaseEnvironment environment = DefaultCouchbaseEnvironment
    .builder()
    .kvEndpoints(2)
    .build();
CouchbaseCluster cluster = CouchbaseCluster.create(environment);]]></codeblock>

<p>All system properties start with the <codeph>com.couchbase</codeph> prefix.</p>

</section>

<section>
			<title>Configuration Options</title>

			<p>The following tables cover all possible configuration options and explain their usage and
				default values. The tables categorize the options into groups for bootstrapping,
				timeout, reliability, performance, and advanced options.</p>

</section>

        <section>
          <title>Bootstrap Options</title>

    <table frame="all" rowsep="1" colsep="1" id="java-bootstrap-options-ref">
        <title>Bootstrap Options Reference</title>
        <tgroup cols="5">
                    <colspec colname="name" colnum="1" colwidth="1*"/>
                    <colspec colname="bname" colnum="2" colwidth="1.5*"/>
                    <colspec colname="pname" colnum="3" colwidth="1.5*"/>
                    <colspec colname="default" colnum="4" colwidth="1.5*"/>
                    <colspec colname="descr" colnum="5" colwidth="4*"/>
                    <thead>
                        <row>
                            <entry>Name</entry>
                            <entry>Builder</entry>
                            <entry>Property</entry>
                            <entry>Default</entry>
                            <entry>Description</entry>
                        </row>
                    </thead>
                    <tbody>
                        <row>
                            <entry>Enabling Encryption</entry>
                            <entry><codeph>sslEnabled \(boolean)</codeph></entry>
                            <entry><codeph>sslEnabled</codeph></entry>
                            <entry><codeph>false</codeph></entry>
                            <entry>If encrypted communication should be enabled. This feature is
                                only available against a Couchbase Server 3.0 EE cluster or later,
                                and setting it to true implies you also set a value for
                                    <codeph>sslKeystoreFile</codeph> and
                                    <codeph>sslKeystorePassword</codeph>. Please see the <xref
                                    href="managing-connections.dita">Managing Connections</xref>
                                section for more details on how to set it up properly.</entry>
                        </row>
                        <row>
                            <entry>SSL Keystore Location</entry>
                            <entry><codeph>sslKeystoreFile \(String)</codeph></entry>
                            <entry><codeph>sslKeystore \File</codeph></entry>
                            <entry><codeph>[empty]</codeph></entry>
                            <entry>The location to the JVM keystore where the certificates are
                                stored. This feature is only available against a Couchbase Server
                                3.0 EE cluster or later. See the "Connection Management" section for
                                more details on how to set it up properly.</entry>
                        </row>
                        <row>
                            <entry>Custom SSL Keystore</entry>
                            <entry><codeph>sslKeystore \(KeyStore)</codeph></entry>
                            <entry><codeph>-</codeph></entry>
                            <entry><codeph>[empty]</codeph></entry>
                            <entry>A custom KeyStore instance instead of creating one through the
                                filepath. Allows for heavily customized and differently loaded
                                keystores.</entry>
                        </row>
                        <row>
                            <entry>SSL Keystore Password</entry>
                            <entry><codeph>sslKeystore \Password(String)</codeph></entry>
                            <entry><codeph>sslKeystore \Password</codeph></entry>
                            <entry><codeph>[empty]</codeph></entry>
                            <entry>The password of the JVM keystore where the certificates are
                                stored. This feature is only available against a Couchbase Server
                                3.0 EE cluster or later. Please see the "Connection Management"
                                section for more details on how to set it up properly.</entry>
                        </row>
                        <row>
                            <entry>Config Loading through HTTP</entry>
                            <entry><codeph>bootstrapHttp \Enabled(boolean)</codeph></entry>
                            <entry><codeph>bootstrapHttp \Enabled</codeph></entry>
                            <entry><codeph>true</codeph></entry>
                            <entry>If it should be possible for the client to bootstrap and grab
                                configurations over the HTTP port 8091 (and also attach a streaming
                                connection). If you are running Couchbase Server 2.2 or earlier,
                                this setting must be set to true. Against newer clusters it can be
                                disabled, but it doesn't hurt to keep it enabled as a last-resort
                                fallback option. Also, if configuration loading through carrier
                                publication is manually disabled, this option is used as a fallback.
                                If both option are disabled, the client is not able to function
                                properly. If you don't have a good reason to disable it (for example
                                as instructed by Couchbase Support), keep it enabled.</entry>
                        </row>
                        <row>
                            <entry>Config HTTP Non-Encrypted Port</entry>
                            <entry><codeph>bootstrapHttp \DirectPort(int)</codeph></entry>
                            <entry><codeph>bootstrapHttp \DirectPort</codeph></entry>
                            <entry><codeph>8091</codeph></entry>
                            <entry>The port which is used if encryption is not enabled and the
                                client needs to bootstrap through HTTP. In general, there is no need
                                to change this value (unless you run a custom Couchbase Server build
                                during development or testing that runs on different ports).</entry>
                        </row>
                        <row>
                            <entry>Config HTTP Encrypted Port</entry>
                            <entry><codeph>bootstrapHttp \SslPort(int)</codeph></entry>
                            <entry><codeph>bootstrapHttp \SslPort</codeph></entry>
                            <entry><codeph>18091</codeph></entry>
                            <entry>The port which is used if encryption is enabled and the client
                                needs to bootstrap through HTTP. In general, there is no need to
                                change this value (unless you run a custom Couchbase Server build
                                during development or testing that runs on different ports).</entry>
                        </row>
                        <row>
                            <entry>Config Loading through Carrier Publication</entry>
                            <entry><codeph>bootstrapCarrier \Enabled(boolean)</codeph></entry>
                            <entry><codeph>bootstrapCarrier \Enabled</codeph></entry>
                            <entry><codeph>true</codeph></entry>
                            <entry>If you are running Couchbase Server 2.5 or later, this is the
                                preferred way to bootstrap and grab configurations. It is not done
                                over HTTP, but through the key-value connections automatically. If
                                this setting is manually disabled, the client will fallback to HTTP
                                (if enabled). If both option are disabled, the client is not able to
                                function properly. If you don't have a good reason to disable it
                                (for example as instructed by Couchbase Support), keep it
                                enabled.</entry>
                        </row>
                        <row>
                            <entry>Config Carrier Non-Encrypted Port</entry>
                            <entry><codeph>bootstrapCarrier \DirectPort(int)</codeph></entry>
                            <entry><codeph>bootstrapCarrier \DirectPort</codeph></entry>
                            <entry><codeph>11210</codeph></entry>
                            <entry>The port which is used if encryption is not enabled and the
                                client needs to bootstrap through carrier publication. In general,
                                there is no need to change this value (unless you run a custom
                                Couchbase Server build during development or testing that runs on
                                different ports).</entry>
                        </row>
                        <row>
                            <entry>Config Carrier Encrypted Port</entry>
                            <entry><codeph>bootstrapCarrier \SslPort(int)</codeph></entry>
                            <entry><codeph>bootstrapCarrier \SslPort</codeph></entry>
                            <entry><codeph>11207</codeph></entry>
                            <entry>The port which is used if encryption is enabled and the client
                                needs to bootstrap through carrier publication. In general, there is
                                no need to change this value (unless you run a custom Couchbase
                                Server build during development or testing that runs on different
                                ports).</entry>
                        </row>
                        <row>
                            <entry>DNS SRV Enabled</entry>
                            <entry><codeph>dnsSrvEnabled \(boolean)</codeph></entry>
                            <entry><codeph>dnsSrvEnabled</codeph></entry>
                            <entry><codeph>false</codeph></entry>
                            <entry>Enable manually if you explicitly want to grab a bootstrap node
                                list through a DNS SRV record. See the "Connection Management"
                                section for more information on how to use it properly.</entry>
                        </row>
                        <row>
                            <entry>Mutation Tokens Enabled</entry>
                            <entry><codeph>mutationTokens \Enabled(boolean)</codeph></entry>
                            <entry><codeph>mutationTokens \Enabled</codeph></entry>
                            <entry><codeph>false</codeph></entry>
                            <entry>If mutation tokens should be enabled, adding more overhead to
                                every mutation but providing enhanced durability requirements as
                                well as advanced N1QL querying capabilities.</entry>
                        </row>
                    </tbody>
                </tgroup>
        </table>
		</section>

		<section>
      <title>Timeout Options</title>

      <p>Timeouts apply only for blocking operations. All asynchronous operations must chain in their
				own <codeph>timeout()</codeph> operators in order to apply a timeout. All default values
				can be overridden through the overloaded methods that accept both a time and time unit.
				All timeouts are reasonable defaults and should be adjusted to the environments after
				profiling the expected latencies.</p>

      <table frame="all" rowsep="1" colsep="1" id="java-timeout-options-ref">
          <title>Timeout Options Reference</title>
          <tgroup cols="5">
              <colspec colname="name" colnum="1" colwidth="1*"/>
              <colspec colname="bname" colnum="2" colwidth="1*"/>
              <colspec colname="pname" colnum="3" colwidth="1*"/>
              <colspec colname="default" colnum="4" colwidth="1*"/>
              <colspec colname="descr" colnum="5" colwidth="3*"/>
              <thead>
                  <row>
                      <entry>Name</entry>
                      <entry>Builder</entry>
                      <entry>Property</entry>
                      <entry>Default</entry>
                      <entry>Description</entry>
                  </row>
              </thead>
              <tbody>
                  <row>
                      <entry>Key-Value Timeout</entry>
                      <entry><codeph>kvTimeout \
                          (long)</codeph></entry>
                      <entry><codeph>kvTimeout</codeph></entry>
                      <entry><codeph>2500ms</codeph></entry>
                      <entry>The Key/Value default timeout is used on all blocking operations which are performed on a
							specific key if not overridden by a custom timeout. It does not affect
							asynchronous operations. This includes all commands like get(),
							getFromReplica() and all mutation commands.</entry>
                  </row>
                  <row>
                      <entry>View Timeout</entry>
                      <entry><codeph>viewTimeout \
                          (long)</codeph></entry>
                      <entry><codeph>viewTimeout</codeph></entry>
                      <entry><codeph>75000ms</codeph></entry>
                      <entry>The View timeout is used on both regular and geospatial view operations if not overridden
							by a custom timeout. It does not affect asynchronous operations. Note that
							it is set to such a high timeout compared to key/value since it can affect
							hundreds or thousands of rows. Also, if there is a node failure during the
							request the internal cluster timeout is set to 60 seconds.</entry>
                  </row>
                  <row>
                      <entry>Query Timeout</entry>
                      <entry><codeph>queryTimeout \(long)</codeph></entry>
                      <entry><codeph>queryTimeout</codeph></entry>
                      <entry><codeph>75000ms</codeph></entry>
                      <entry>The Query timeout is used on all N1QL query operations if not overridden by a custom timeout. It does not affect asynchronous operations. Note that it is set to
							such a high timeout compared to key/value since it can affect hundreds or
							thousands of rows.</entry>
                  </row>
                  <row>
                      <entry>Connect Timeout</entry>
                      <entry><codeph>connectTimeout \(long)</codeph></entry>
                      <entry><codeph>connect \Timeout</codeph></entry>
                      <entry><codeph>5000ms</codeph></entry>
                      <entry>The connect timeout is used when a Bucket is opened and if not
                                overridden by a custom timeout. It does not affect asynchronous
                                operations. If you feel the urge to change this value to something
                                higher, there is a good chance that your network is not properly set
                                up. Opening a bucket should in practice not take longer than a
                                second on a reasonably fast network.</entry>
                  </row>
                  <row>
                      <entry>Disconnect Timeout</entry>
                      <entry><codeph>disconnect \Timeout(long)</codeph></entry>
                      <entry><codeph>disconnect \Timeout</codeph></entry>
                      <entry><codeph>25000ms</codeph></entry>
                      <entry>The disconnect timeout is used when a Cluster is disconnected or a Bucket is closed
							synchronously and if not overridden by a custom timeout. It does not affect
							asynchronous operations. A timeout is applied here always to make sure that
							your code does not get stuck at shutdown. 25 seconds should provide enough
							room to drain all outstanding operations properly, but make sure to adapt
							this timeout to fit your application requirements.</entry>
                  </row>
                  <row>
                      <entry>Management Timeout</entry>
                      <entry><codeph>management \Timeout(long)</codeph></entry>
                      <entry><codeph>management \Timeout</codeph></entry>
                      <entry><codeph>75000ms</codeph></entry>
                      <entry>The management timeout is used on all synchronous BucketManager and
							ClusterManager operations and if not overridden by a custom timeout. It set
							to a quite high timeout because some operations might take a longer time to
							complete (for example flush).</entry>
                  </row>
                  <row>
                      <entry>Socket Connect Timeout</entry>
                      <entry><codeph>socketConnect \Timeout(int)</codeph></entry>
                      <entry><codeph>socketConnect \Timeout</codeph></entry>
                      <entry><codeph>1000ms</codeph></entry>
                      <entry>The amount of time the SDK will wait on the socket connect until an error is raised and handled.</entry>
                  </row>
                </tbody>
              </tgroup>
          </table>
		</section>

		<section><title>Reliability Options</title>

    <table frame="all" rowsep="1" colsep="1" id="java-reliability-options-ref">
        <title>Reliability Options Reference</title>
        <tgroup cols="5">
            <colspec colname="name" colnum="1" colwidth="1*"/>
            <colspec colname="bname" colnum="2" colwidth="1*"/>
            <colspec colname="pname" colnum="3" colwidth="1*"/>
            <colspec colname="default" colnum="4" colwidth="1*"/>
            <colspec colname="descr" colnum="5" colwidth="3*"/>
            <thead>
                <row>
                    <entry>Name</entry>
                    <entry>Builder</entry>
                    <entry>Property</entry>
                    <entry>Default</entry>
                    <entry>Description</entry>
                </row>
            </thead>
            <tbody>
                <row>
                    <entry>Reconnect Delay</entry>
                    <entry><codeph>reconnectDelay \(Delay)</codeph></entry>
                    <entry><codeph>-</codeph></entry>
                    <entry><codeph>Exponential between 32ms and 4096ms</codeph></entry>
                    <entry>The reconnect delay defines the time intervals between a socket getting closed on the SDK
							side and trying to reopen (reconnect) to it. The default is to retry
							relatively quickly (32ms) and then gradually approach 4 second intervals, so
							that in case a server is longer down than usual the clients do not flood the
							server with socket requests. Feel free to tune this interval based on your
							application requirements. Applying a very large ceiling may lead to longer
							down times than needed, while very short delays may flood the target node
							and spam the network unnecessarily.</entry>
                </row>
                <row>
                    <entry>Retry Delay</entry>
                    <entry><codeph>retryDelay \(Delay)</codeph></entry>
                    <entry><codeph>-</codeph></entry>
                    <entry><codeph>Exponential between 100µs and 100ms</codeph></entry>
                    <entry>When a request needs to be retried for some reason (for example if the retry strategy is
							best effort and the target node is not reachable), this delay configures the
							boundaries. An internal counter tracks the number of retries for a given
							request and it gradually increases by default from a very quick 100
							microseconds up to a 100 millisecond delay. The operation will be retried
							until it succeeds or the maximum request lifetime is reached. If you find
							yourself wanting to tweak this value to a very low setting, you might want
							to consider a different retry strategy like "fail fast" to get tighter
							control on the retry handling yourself.</entry>
                </row>
                <row>
                    <entry>Retry Strategy</entry>
                    <entry><codeph>retryStrategy \(RetryStrategy)</codeph></entry>
                    <entry><codeph>-</codeph></entry>
                    <entry><codeph>Best Effort</codeph></entry>
                    <entry>The retry strategy decides if an operation should be retried or canceled. While
							implementing a custom strategy is fairly advanced, the SDK ships with two
							out of the box: BestEffortRetryStrategy and FailFastRetryStrategy. The first
							one will retry the operation until it either succeeds or the maximum request
							lifetime is reached. The fail fast strategy will cancel it right away and
							therefore the client needs to be prepared to retry on its own, but gets much
							tighter control on when and how to retry. See the advanced section in the
							documentation on more specific information on retry strategies and failure
							management.</entry>
                </row>
                <row>
                    <entry>Maximum Request Lifetime</entry>
                    <entry><codeph>maxRequest \Lifetime(long)</codeph></entry>
                    <entry><codeph>maxRequest \Lifetime</codeph></entry>
                    <entry><codeph>75000ms</codeph></entry>
                    <entry>The maximum request lifetime is used by the best effort retry strategy to decide if its
							time to cancel the request instead of retrying it again. This is needed in
							order to prevent requests from circling around forever and occupying
							precious slots in the request ring buffer. Make sure to set this higher than
							the largest timeout in your application, otherwise you risk requests being
							canceled prematurely. This is why the default value is set to 75 seconds,
							which is the highest default timeout on the environment.</entry>
                </row>
                <row>
                    <entry>Socket Keepalive Interval</entry>
                    <entry><codeph>keepAlive \Interval(long)</codeph></entry>
                    <entry><codeph>keepAlive \Interval</codeph></entry>
                    <entry><codeph>30000ms</codeph></entry>
                    <entry>To avoid nasty firewalls and other network equipment cutting off stale TCP connections, at
							the configured interval the client will send a heartbeat keepalive message
							to the remote node and port. This only happens if for the given amount of
							time no traffic has happened, so if a socket is busy sending data back and
							forth it will have no effect. If you set this value to 0, no keepalive will
							be sent over the sockets.</entry>
                </row>
              </tbody>
          </tgroup>
        </table>
		</section>

		<section><title>Performance Options</title>

    <table frame="all" rowsep="1" colsep="1" id="java-performance-options-ref">
        <title>Performance Options Reference</title>
        <tgroup cols="5">
            <colspec colname="name" colnum="1" colwidth="1*"/>
            <colspec colname="bname" colnum="2" colwidth="1*"/>
            <colspec colname="pname" colnum="3" colwidth="1*"/>
            <colspec colname="default" colnum="4" colwidth="1*"/>
            <colspec colname="descr" colnum="5" colwidth="3*"/>
            <thead>
                <row>
                    <entry>Name</entry>
                    <entry>Builder</entry>
                    <entry>Property</entry>
                    <entry>Default</entry>
                    <entry>Description</entry>
                </row>
            </thead>
            <tbody>
                <row>
                    <entry>Observe Interval</entry>
                    <entry><codeph>observeInterval \Delay(Delay)</codeph></entry>
                    <entry><codeph>-</codeph></entry>
                    <entry><codeph>Exponential between 10µs and 100ms</codeph></entry>
                    <entry>The way PersistTo and ReplicateTo work is that once the regular mutation operation
							succeeds, the key state on the target nodes is polled until the desired
							state is reached. Since replication and persistence latency differs greatly
							on servers (fast or slow networks and disks), this value can be tuned for
							maximum efficiency. The tradeoffs to consider here is how quickly the
							desired state is detected as well as how much the SDK will spam the network.
							The default is an exponential delay, starting with very short intervals but
							very quickly approaching the 100 milliseconds if replication or persistence
							takes longer than expected. You should monitor the average persistence and
							replication latency and adjust the delay accordingly.</entry>
                </row>
                <row>
                    <entry>Key/Value Endpoints per Node</entry>
                    <entry><codeph>kvEndpoints(int)</codeph></entry>
                    <entry><codeph>kvEndpoints</codeph></entry>
                    <entry><codeph>1</codeph></entry>
                    <entry>The number of actual endpoints (sockets) to open per Node in the cluster against the
							Key/value service. By default, for every node in the cluster one socket is
							opened where all traffic is pushed through. That way the SDK implicitly
							benefits from network batching characteristics when the workload increases.
							If you suspect based on profiling and benchmarking that the socket is
							saturated you can think about slightly increasing it to have more "parallel
							pipelines". This might be especially helpful if you need to push large
							documents through it. The recommendation is keeping it at 1 unless there is
							other evidence.</entry>
                </row>
                <row>
                    <entry>View Endpoints per Node</entry>
                    <entry><codeph>viewEndpoints(int)</codeph></entry>
                    <entry><codeph>viewEndpoints</codeph></entry>
                    <entry><codeph>1</codeph></entry>
                    <entry>The number of actual endpoints (sockets) to open per node in
							the cluster against the view service. By default only one socket is opened
							to avoid unnecessary wasting resources. If you plan to run a view heavy
							workload, especially paired with larger responses, increasing this value
							significantly (most likely between 5 and 10) can provide greater throughput.
							Keep in mind that these sockets will then be always open, even when no load
							is passed through. We recommend that you tune this value based on evidence
							obtained during benchmarking with a real workload. If no view load is
							expected, setting this value explicitly to 0 can avoid one socket to 8092
							per node.</entry>
                </row>
                <row>
                    <entry>Query Endpoints per Node</entry>
                    <entry><codeph>query \
                        Endpoints(int)</codeph></entry>
                    <entry><codeph>query \
                        Endpoints</codeph></entry>
                    <entry><codeph>1</codeph></entry>
                    <entry>The number of actual endpoints (sockets) to open per Node in the cluster against the Query
							(N1QL) service. By default only one socket is opened to avoid unnecessary
							wasting resources. If you plan to run a query heavy workload, especially
							paired with larger responses, increasing this value significantly (most
							likely between 5 and 10) can provide greater throughput. Keep in mind that
							these sockets will then be always open, even when no load is passed through.
							We are recommending to tune this value based on evidence during benchmarking
							with a real workload. If no query load is expected, setting this value
							explicitly to 0 can avoid one socket to 8093 per node.</entry>
                </row>
                <row>
                    <entry>Search Endpoints per Node</entry>
                    <entry><codeph>search \Endpoints(int)</codeph></entry>
                    <entry><codeph>search \Endpoints</codeph></entry>
                    <entry><codeph>1</codeph></entry>
                    <entry>The number of actual endpoints (sockets) to open per Node in the cluster against the Search
							(FTS) service. By default only one socket is opened to avoid unnecessary
							wasting resources. If you plan to run a query heavy workload, especially
							paired with larger responses, increasing this value significantly (most
							likely between 5 and 10) can provide greater throughput. Keep in mind that
							these sockets will then be always open, even when no load is passed through.
							We are recommending to tune this value based on evidence during benchmarking
							with a real workload. If no query load is expected, setting this value
							explicitly to 0 can avoid one socket to 8094 per node.</entry>
                </row>
                <row>
                    <entry>I/O Thread Pool Size</entry>
                    <entry><codeph>ioPoolSize(int)</codeph></entry>
                    <entry><codeph>ioPoolSize</codeph></entry>
                    <entry><codeph>Runtime# \available \Processors()</codeph></entry>
                    <entry>The number of threads in the I/O thread pool. This defaults to the number of available
							processors that the runtime returns (which, as a well known fact, sometimes
							does not represent the actual number of processors). Every thread represents
							an internal event loop where all needed socket are multiplexed on. The
							default value should be fine most of the time, it may only need to be tuned
							if you run a very large number of nodes in the cluster or the runtime value
							is incorrect. As a rule of thumb, it should roughly correlate with the
							number of cores available to the JVM.</entry>
                </row>
                <row>
                    <entry>Computation Thread Pool Size</entry>
                    <entry><codeph>computation \PoolSize(int)</codeph></entry>
                    <entry><codeph>computation \PoolSize</codeph></entry>
                    <entry><codeph>Runtime# \available \Processors()</codeph></entry>
                    <entry>The number of threads in the computation thread pool. This defaults to the number of
							available processors that the runtime returns (which, as a well known fact,
							sometimes does not represent the actual number of processors). Every thread
							represents an internal event loop where all needed computation tasks are
							run. The default value should be fine most of the time, it might only need
							to be tuned if you run more than usual CPU-intensive tasks and profiling the
							application indicates fully saturated threads in the pool. As a rule of
							thumb, it should roughly correlate with the number of cores available to the
							JVM.</entry>
                </row>
                <row>
                    <entry>I/O Pool Group</entry>
                    <entry><codeph>ioPool \(EventLoopGroup)</codeph></entry>
                    <entry><codeph>-</codeph></entry>
                    <entry><codeph>NioEvent \
                        LoopGroup</codeph></entry>
                    <entry>For those who want the last drop of performance, on Linux Netty provides a way to use edge
							triggered epoll instead of going through JVM NIO. This provides better
							throughput, lower latency and less garbage. Note that this mode has not been
							tested by Couchbase and therefore is not supported officially. If you like
							to take a walk on the wild side, you can find out more here: <xref href="http://netty.io/wiki/native-transports.html" format="html" scope="external">Netty Native-transports.</xref></entry>
                </row>
                <row>
                    <entry>TCP Nodelay</entry>
                    <entry><codeph>tcpNodelay \Enabled(boolean)</codeph></entry>
                    <entry><codeph>tcpNodelay \
                        Enabled</codeph></entry>
                    <entry><codeph>true</codeph></entry>
                    <entry>By default, TCP Nodelay is turned on (which in effect turns off "nagleing"), and if
possible negotiated with the server as well. If this is set to false,
"nagleing" is turned on. Make sure to only turn off TCP nodelay if you know
what you are doing, because it can lead to decreased performance.</entry>
                </row>
                <row>
                    <entry>Run Callbacks on the I/O Pool</entry>
                    <entry><codeph>callbacks \OnIoPool \(boolean)</codeph></entry>
                    <entry><codeph>callbacks \OnIoPool</codeph></entry>
                    <entry><codeph>false</codeph></entry>
                    <entry>If set to true, all callbacks will not be moved onto the
                    scheduler but rather executed on the IO threads. This can aid performance
                  under high throughput scenarios but extra care must be taken to not block in
                  a callback since this has direct impact on the performance of the I/O loops!</entry>
                </row>
              </tbody>
            </tgroup>
          </table>

		</section>
		<section><title>Advanced Options</title>

    <p>Values for the advanced options listed in the following table should not be changed unless
      there is a very good reason to do so.</p>

      <table frame="all" rowsep="1" colsep="1" id="java-advanced-options-ref">
          <title>Advanced Options Reference</title>
          <tgroup cols="5">
              <colspec colname="name" colnum="1" colwidth="1*"/>
              <colspec colname="bname" colnum="2" colwidth="1*"/>
              <colspec colname="pname" colnum="3" colwidth="1*"/>
              <colspec colname="default" colnum="4" colwidth="1*"/>
              <colspec colname="descr" colnum="5" colwidth="3*"/>
              <thead>
                  <row>
                      <entry>Name</entry>
                      <entry>Builder</entry>
                      <entry>Property</entry>
                      <entry>Default</entry>
                      <entry>Description</entry>
                  </row>
              </thead>
              <tbody>
                  <row>
                      <entry>Request Ring Buffer Size</entry>
                      <entry><codeph>requestBuffer \Size(int)</codeph></entry>
                      <entry><codeph>requestBuffer \Size</codeph></entry>
                      <entry><codeph>16384</codeph></entry>
                      <entry>The size of the request ring buffer where all request initially are stored and then picked
							up to be pushed onto the I/O threads. Tuning this to a lower value will more
							quickly lead to BackpressureExceptions during overload or failure scenarios.
							Setting it to a higher value means backpressure will take longer to occur,
							but more requests will potentially be queued up and more heap space is
							used.</entry>
                  </row>
                  <row>
                      <entry>Response Ring Buffer Size</entry>
                      <entry><codeph>responseBuffer \Size(int)</codeph></entry>
                      <entry><codeph>responseBuffer \Size</codeph></entry>
                      <entry><codeph>16384</codeph></entry>
                      <entry>The size of the response ring buffer where all responses are passed through from the I/O
							threads before the target Observable is completed. Since the I/O threads are
							pushing data in this ring buffer, setting it to a lower value is likely to
							have a negative effect on I/O performance. In general it should be kept in
							line with the request ring buffer size.</entry>
                  </row>
                  <row>
                      <entry>Computation Scheduler</entry>
                      <entry><codeph>scheduler \(Scheduler)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>CoreScheduler</codeph></entry>
                      <entry>The scheduler used for all CPU-intensive, non-blocking computations in the core, client and
							in user space. This is a slightly modified version of the
							ComputationScheduler that ships with RxJava, mainly for the reason to
							manually name threads as needed. Changing the scheduler should be used with
							extra care, especially since lots of internal components also depend on
							it.</entry>
                  </row>
                  <row>
                      <entry>User Agent String</entry>
                      <entry><codeph>userAgent \(String)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>Based on OS, Runtime and SDK Version</codeph></entry>
                      <entry>The user agent string that is used to identify the SDK against the Couchbase Server cluster
							on different occasions, for example when doing a view or query request.
							There is no need to tune that because it is dynamically generated based on
							properties set during build time (based on the package name and version, OS
							and runtime).</entry>
                  </row>
                  <row>
                      <entry>Package Name and Version Identifier</entry>
                      <entry><codeph>packageNameAnd \Version(String)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>Based on SDK Version</codeph></entry>
                      <entry>The package name and identifier is used as part of the user agent string and in the
							environment info output to see which version of the SDK the application is
							running. There is no need to change it because it is dynamically generated
							based on properties set during build time.</entry>
                  </row>
                  <row>
                      <entry>Event Bus</entry>
                      <entry><codeph>eventBus \(EventBus)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>DefaultEventBus</codeph></entry>
                      <entry>The event bus implementation used to transport system, performance and debug events from
							producers to subscribers. The default implementation is based on an internal
							RxJava Subject which does not cache the values and only pushes subsequent
							events to the subscribers. If you provide a custom implementation, double
							check that it fits with the contract of the event bus as documented.</entry>
                  </row>
                  <row>
                      <entry>DCP Enabled</entry>
                      <entry><codeph>dcpEnabled \(boolean)</codeph></entry>
                      <entry><codeph>dcpEnabled</codeph></entry>
                      <entry><codeph>false</codeph></entry>
                      <entry>DCP is not ready for prime time in clients, but this configuration switch is available
							because all parameters from the core-io module are inherited. If you have
							active need for DCP, get in touch with the Couchbase team.</entry>
                  </row>
                  <row>
                      <entry>DCP Connection Buffer Size</entry>
                      <entry><codeph>dcpConnection \BufferSize(int)</codeph></entry>
                      <entry><codeph>dcpConnection \
                          BufferSize</codeph></entry>
                      <entry><codeph>20971520 (20MiB)</codeph></entry>
                      <entry>Sets the size of the buffer to control speed of DCP producer. The s
                        erver will stop emitting data if the current value of the buffer reach
                        this limit. Set it to zero to disable DCP flow control.</entry>
                  </row>

                  <row>
                      <entry>DCP Connection Buffer Ack Threshold</entry>
                      <entry><codeph>dcpConnection \BufferAck \Threshold(double)</codeph></entry>
                      <entry><codeph>dcpConnection \BufferAck \Threshold</codeph></entry>
                      <entry><codeph>0.2</codeph></entry>
                      <entry>When a DCP connection read bytes reaches this percentage of
                        the dcpConnectionBufferSize, a DCP Buffer Acknowledge message is sent
                        to the server to signal producer how much data has been processed.</entry>
                  </row>

                  <row>
                      <entry>DCP Connection Name</entry>
                      <entry><codeph>dcpConnection \Name(String)</codeph></entry>
                      <entry><codeph>dcpConnection \Name</codeph></entry>
                      <entry><codeph>dcp/core-io</codeph></entry>
                      <entry>Sets default name for DCP connection. It is used to
                      identify streams on the server.</entry>
                  </row>

                  <row>
                      <entry>Buffer Pooling Enabled</entry>
                      <entry><codeph>bufferPooling \Enabled(boolean)</codeph></entry>
                      <entry><codeph>bufferPooling \Enabled</codeph></entry>
                      <entry><codeph>true</codeph></entry>
                      <entry>If the SDK is suspected to leak buffers (it pools buffers in its IO layer for performance)
							you can set this field to false. This will make sure buffers are not pooled,
							but remember the tradeoff here is higher GC pressure on the system. Only
							turn off to prevent a memory leak from happening (in production). If you
							suspect a memory leak, please open a bug ticket.</entry>
                  </row>
                  <row>
                      <entry>Runtime Metrics Collector</entry>
                      <entry><codeph>runtimeMetrics \CollectorConfig \(Metrics \CollectorConfig)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>DefaultMetrics \CollectorConfig</codeph></entry>
                      <entry>The configuration of the runtime metrics collector can be modified (or completely
							disabled). By default, it will emit an event every hour.</entry>
                  </row>
                  <row>
                      <entry>Network Latency Metrics Collector</entry>
                      <entry><codeph>networkLatency \MetricsCollector \Config(Latency \MetricsCollector \Config)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>DefaultLatency \Metrics Collector \Config</codeph></entry>
                      <entry>The configuration of the network latency metrics collector can be modified (or completely
							disabled). By default, it will emit an event every hour, but collect the
							stats all the time.</entry>
                  </row>
                  <row>
                      <entry>Default Metrics Consumer</entry>
                      <entry><codeph>defaultMetrics \LoggingConsumer \
                          (boolean, CouchbaseLogLevel, OutputFormat)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>enabled, INFO, JSON</codeph></entry>
                      <entry>The default metric consumer which will log all metric events. You can configure if it
							should be enabled, as well as the log level and the target output
							format.</entry>
                  </row>
                  <row>
                      <entry>Request Buffer Wait Strategy</entry>
                      <entry><codeph>requestBuffer \
                          WaitStrategy \
                          (WaitStrategy)</codeph></entry>
                      <entry><codeph>-</codeph></entry>
                      <entry><codeph>BlockingWait \
                          Strategy</codeph></entry>
                      <entry>The underlying request buffer can use a different wait strategy
                        which can be used to get better performance under high throughput/low
                        latency circumstances, trading CPU time for it. This is an export option,
                        only use it if you are comfortable with the LMAX Disruptor and know the
                        impact of plugging in a different strategy!</entry>
                  </row>
                        <row>
                            <entry>Automatic Observable Resource Release Time Period</entry>
                            <entry><codeph>autorelease\ After(int)</codeph></entry>
                            <entry><codeph>-</codeph></entry>
                            <entry><codeph>2000</codeph></entry>
                            <entry>The time period in milliseconds that a subscriber needs to
                                subscribe to the observable. After this period, the resources
                                involved in the observable are released and can't be subscribed to
                                anymore. This is required to avoid leaking data, it also needs to be
                                a short time bound to avoid having the observable move into older GC
                                generations unnecessarily, which harms performance.</entry>
                        </row>
                </tbody>
              </tgroup>
            </table>
		</section>
	</body>

</topic>
