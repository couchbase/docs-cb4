<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_cn2_5ck_r5">
    <title>Release Notes</title>
    <shortdesc>Release notes for the 1.2 version of the Spark connector.</shortdesc>
<conbody>
       <section><title>Couchbase Spark Connector 1.2.0 GA (May 2016)</title> Version 1.2.0 is
            the first stable release of the 1.2.x series. It brings support for Spark 1.6
            and the following enhancements and bugfixes:

            <p><b>Spark Core</b></p>

            <ul>
                <li>Support for Apache Spark 1.6.x</li>
                <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-37" format="html"
                        scope="external">SPARKC-37</xref>: Both Java and Scala APIs now export
                    Couchbase view, spatial view, and N1QL query APIs on RDDs in addition to the
                        <codeph>SparkContext</codeph>.</li>
                <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-46" format="html"
                        scope="external">SPARKC-46</xref>: Subdocument Lookups are supported on the
                    RDDs and the SparkContext (only supported with Couchbase Server 4.5).</li>
            </ul>

            <p><b>Spark SQL</b></p>

            <ul>
                <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-41" format="html"
                        scope="external">SPARKC-41</xref>: Manual override of the <codeph>schemaFilter</codeph> has been fixed. It is now possible to define a filter like this:
<codeblock outputclass="language-scala"><![CDATA[sqlContext.read
  .option("bucket","travel-sample")
  .option("schemaFilter", "type = 'airline'")
  .couchbase()]]></codeblock>
                      </li>
                <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-42" format="html"
                        scope="external">SPARKC-42</xref>: The SparkSQL <codeph>count()</codeph> operator now works, a bug has been fixed so that
                      if SparkSQL doesn't pass in required columns they are transformed to a <codeph>*</codeph> query.</li>
                      <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-30" format="html"
                              scope="external">SPARKC-30</xref>: It is now possible to provide a manual schema as well as a custom schema filter.</li>
                              <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-43" format="html"
                                      scope="external">SPARKC-43</xref>: The Java API can now use Spark SQL directly. See the Java API documentation for more information.</li>
                                      <li><xref href="https://www.couchbase.com/issues/browse/SPARKC-47" format="html"
                                              scope="external">SPARKC-47</xref>: SparkSQL Filter expression support has been extended to support all Spark Filters, including nested ones.</li>
            </ul>

            <p><b>Spark Streaming</b></p>

            <ul>
                <li>The internal implementation has been updated to the latest release but <b>is
                        still experimental</b>. Note that the <codeph>FromBeginning</codeph> is
                    implemented, but <codeph>FromNow</codeph> still has some known issues which will
                    be fixed in later releases. Also, cluster rebalance support is not yet available
                    and will follow.</li>
            </ul>
        </section>

        </conbody>
    </concept>
